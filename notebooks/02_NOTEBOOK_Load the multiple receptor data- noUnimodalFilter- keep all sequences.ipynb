{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My unimodal filter looks for transitions from ascending to descending. It counts how many peaks are found\n",
    "# if there are 2 or more peaks, it is bimodal.\n",
    "\n",
    "# Often times it is difficult to distinguish signal from noise. If the change in probability is below the threshold change\n",
    "# I assume that transition observed is noise. \n",
    "\n",
    "\n",
    "def isTransitionArrayUnimodal(myArray):\n",
    "    myArray \n",
    "    \n",
    "    momentum =0\n",
    "    transition = 0\n",
    "    \n",
    "    for each in myArray:\n",
    "        if each==0:\n",
    "            pass\n",
    "        else:\n",
    "            if(momentum==1 and each == -1):\n",
    "                transition+=1\n",
    "                momentum= each\n",
    "            elif( momentum ==-1 and each == 1):\n",
    "                transition+=1\n",
    "                momentum= each\n",
    "            else:\n",
    "                momentum= each\n",
    "    \n",
    "    #print transition\n",
    "    \n",
    "    if(transition==1 or transition ==0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def isDistributionUnimodal(row,prefix):\n",
    "    \n",
    "    myDistribution = list(row[[prefix+str(each) for each in range(12)]].squeeze())\n",
    "    #print myDistribution\n",
    "    \n",
    "    \n",
    "    #Differences greater than this are set as a change in sign\n",
    "    \n",
    "    threshold=0.04\n",
    "    \n",
    "    \n",
    "    myTransitionArray = []\n",
    "    for i in range(11):\n",
    "        currentP,nextP = myDistribution[i],myDistribution[i+1]\n",
    "        myDiff = nextP-currentP\n",
    "        if(np.abs(myDiff)<threshold):\n",
    "            myDiff=0        \n",
    "        \n",
    "        myTransitionArray.append(np.sign(myDiff))\n",
    "    #print myTransitionArray\n",
    "\n",
    "    return isTransitionArrayUnimodal(myTransitionArray)\n",
    "    \n",
    "    \n",
    "    #print myTransitionArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BFL1 100NM\n",
    "#MCL1 1NM\n",
    "#Bclxl 1NM\n",
    "#Bclxl 100NM\n",
    "\n",
    "bfl1_solo = pd.read_pickle(\"/home/vxue/data/sort_bfl1/SORTCERY_009/bfl1_data_usearch.pickle\")\n",
    "f100_2015 = pd.read_pickle(\"/home/vxue/data/sort_2015/postUsearch/multiplex_bfl1_100.pickle\")\n",
    "\n",
    "\n",
    "x1_2015 = pd.read_pickle(\"/home/vxue/data/sort_2015/postUsearch/multiplex_bclxl_1nm.pickle\")\n",
    "x100_2015 = pd.read_pickle(\"/home/vxue/data/sort_2015/postUsearch/multiplex_bclxl_100.pickle\")\n",
    "\n",
    "\n",
    "allDF2 = pickle.load(open(\"/home/vxue/data/sort_20161109/sort_006/allData.pickle\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 5869\n",
      "x1r 6120\n",
      "f100 4186\n",
      "f100r 7545\n",
      "m1 6412\n",
      "m1r 6139\n",
      "x100 4550\n",
      "x100r 6489\n"
     ]
    }
   ],
   "source": [
    "print('x1',len(allDF2[1]))\n",
    "print('x1r',len(x1_2015))\n",
    "print('f100',len(f100_2015))\n",
    "print('f100r',len(bfl1_solo))\n",
    "print('m1',len(allDF2[2]))\n",
    "print('m1r',len(allDF2[4]))\n",
    "print('x100',len(x100_2015))\n",
    "print('x100r',len(allDF2[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqueName = ['160906_x100','160902_x1','160826_m1','160819_f100','160831_m1r']\n",
    "uniqueShortName = ['x100','x1','m1','f100','m1r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bfl1_solo['bfl1_isUnimodal'] = bfl1_solo.apply(lambda x :isDistributionUnimodal(x,'bfl1_p'),axis=1)\n",
    "f100_2015['BFL1_100nM_isUnimodal'] = f100_2015.apply(lambda x :isDistributionUnimodal(x,'BFL1_100nM_p'),axis=1)\n",
    "x1_2015['BCL-xl_1nM_isUnimodal'] = x1_2015.apply(lambda x :isDistributionUnimodal(x,'BCL-xl_1nM_p'),axis=1)\n",
    "x100_2015['Bcl-xl_100nM_isUnimodal'] = x100_2015.apply(lambda x :isDistributionUnimodal(x,'Bcl-xl_100nM_p'),axis=1)\n",
    "\n",
    "\n",
    "for i in range(len(allDF2)):\n",
    "    allDF2[i][uniqueShortName[i]+'_isUnimodal'] = allDF2[i].apply(lambda x :isDistributionUnimodal(x,uniqueShortName[i]+'_p'),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6854\n"
     ]
    }
   ],
   "source": [
    "m1 = pd.merge(allDF2[2],allDF2[4],on=('seq','bg'),how='outer')\n",
    "print(len(m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7728\n"
     ]
    }
   ],
   "source": [
    "x100 = pd.merge(x100_2015,allDF2[0],on=('seq','bg'),how='outer')\n",
    "del x100['read']\n",
    "del x100['type']\n",
    "del x100['percent']\n",
    "del x100['count']\n",
    "del x100['uid']\n",
    "del x100['percent_chimera']\n",
    "del x100['parent']\n",
    "del x100['protein']\n",
    "del x100['pValue']\n",
    "del x100['new_parent']\n",
    "del x100['new_protein']\n",
    "del x100['new_seq']\n",
    "del x100['new_new_parent']\n",
    "del x100['numMutFromJustin']\n",
    "del x100['numMutFromLuther']\n",
    "del x100['numMutFromBim']\n",
    "del x100['numMutFromPuma']\n",
    "del x100['mostLikelySource']\n",
    "print(len(x100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7551\n"
     ]
    }
   ],
   "source": [
    "x1 = pd.merge(x1_2015,allDF2[1],on=('seq','bg'),how='outer')\n",
    "del x1['read']\n",
    "del x1['type']\n",
    "del x1['percent']\n",
    "del x1['count']\n",
    "del x1['uid']\n",
    "del x1['percent_chimera']\n",
    "del x1['parent']\n",
    "del x1['protein']\n",
    "del x1['pValue']\n",
    "del x1['new_parent']\n",
    "del x1['new_protein']\n",
    "del x1['new_seq']\n",
    "del x1['new_new_parent']\n",
    "del x1['numMutFromJustin']\n",
    "del x1['numMutFromLuther']\n",
    "del x1['numMutFromBim']\n",
    "del x1['numMutFromPuma']\n",
    "del x1['mostLikelySource']\n",
    "print(len(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f100 = pd.merge(f100_2015,bfl1_solo,on=('seq','bg'),how='outer')\n",
    "del f100['read_x']\n",
    "del f100['type_x']\n",
    "del f100['percent_x']\n",
    "del f100['count_x']\n",
    "del f100['uid_x']\n",
    "del f100['percent_chimera_x']\n",
    "del f100['parent_x']\n",
    "del f100['protein_x']\n",
    "del f100['pValue_x']\n",
    "del f100['new_parent_x']\n",
    "del f100['new_protein_x']\n",
    "del f100['new_seq_x']\n",
    "del f100['new_new_parent_x']\n",
    "del f100['numMutFromJustin']\n",
    "del f100['numMutFromLuther']\n",
    "del f100['numMutFromBim']\n",
    "del f100['numMutFromPuma']\n",
    "del f100['mostLikelySource']\n",
    "del f100['read_y']\n",
    "del f100['type_y']\n",
    "del f100['percent_y']\n",
    "del f100['count_y']\n",
    "del f100['uid_y']\n",
    "del f100['percent_chimera_y']\n",
    "del f100['parent_y']\n",
    "del f100['protein_y']\n",
    "del f100['pValue_y']\n",
    "del f100['new_parent_y']\n",
    "del f100['new_protein_y']\n",
    "del f100['new_seq_y']\n",
    "del f100['new_new_parent_y']\n",
    "del f100['source']\n",
    "print(len(f100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getProtein(x):\n",
    "    return str(Seq(x,generic_dna).translate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1['protein'] = m1.apply(lambda x: getProtein(x.seq),axis=1)\n",
    "x100['protein'] = x100.apply(lambda x: getProtein(x.seq),axis=1)\n",
    "x1['protein'] = x1.apply(lambda x: getProtein(x.seq),axis=1)\n",
    "f100['protein'] = f100.apply(lambda x: getProtein(x.seq),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allSeqs = pd.merge(m1,x100,on=('seq','bg','protein'),how='outer')\n",
    "allSeqs = pd.merge(allSeqs,x1,on=('seq','bg','protein'),how='outer')\n",
    "allSeqs = pd.merge(allSeqs,f100,on=('seq','bg','protein'),how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11321"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allSeqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bg', 'seq', 'm1_p0', 'm1_p1', 'm1_p2', 'm1_p3', 'm1_p4', 'm1_p5',\n",
       "       'm1_p6', 'm1_p7', 'm1_p8', 'm1_p9', 'm1_p10', 'm1_p11',\n",
       "       'm1_expectedValue', 'm1_CN_0', 'm1_CN_1', 'm1_CN_2', 'm1_CN_3',\n",
       "       'm1_CN_4', 'm1_CN_5', 'm1_CN_6', 'm1_CN_7', 'm1_CN_8', 'm1_CN_9',\n",
       "       'm1_CN_10', 'm1_CN_11', 'm1_CN_tot', 'm1_isUnimodal', 'm1r_p0',\n",
       "       'm1r_p1', 'm1r_p2', 'm1r_p3', 'm1r_p4', 'm1r_p5', 'm1r_p6',\n",
       "       'm1r_p7', 'm1r_p8', 'm1r_p9', 'm1r_p10', 'm1r_p11',\n",
       "       'm1r_expectedValue', 'm1r_CN_0', 'm1r_CN_1', 'm1r_CN_2', 'm1r_CN_3',\n",
       "       'm1r_CN_4', 'm1r_CN_5', 'm1r_CN_6', 'm1r_CN_7', 'm1r_CN_8',\n",
       "       'm1r_CN_9', 'm1r_CN_10', 'm1r_CN_11', 'm1r_CN_tot',\n",
       "       'm1r_isUnimodal', 'protein', 'Bcl-xl_100nM_p0', 'Bcl-xl_100nM_p1',\n",
       "       'Bcl-xl_100nM_p2', 'Bcl-xl_100nM_p3', 'Bcl-xl_100nM_p4',\n",
       "       'Bcl-xl_100nM_p5', 'Bcl-xl_100nM_p6', 'Bcl-xl_100nM_p7',\n",
       "       'Bcl-xl_100nM_p8', 'Bcl-xl_100nM_p9', 'Bcl-xl_100nM_p10',\n",
       "       'Bcl-xl_100nM_p11', 'Bcl-xl_100nM_expectedValue',\n",
       "       'Bcl-xl_100nM_CN_0', 'Bcl-xl_100nM_CN_1', 'Bcl-xl_100nM_CN_2',\n",
       "       'Bcl-xl_100nM_CN_3', 'Bcl-xl_100nM_CN_4', 'Bcl-xl_100nM_CN_5',\n",
       "       'Bcl-xl_100nM_CN_6', 'Bcl-xl_100nM_CN_7', 'Bcl-xl_100nM_CN_8',\n",
       "       'Bcl-xl_100nM_CN_9', 'Bcl-xl_100nM_CN_10', 'Bcl-xl_100nM_CN_11',\n",
       "       'Bcl-xl_100nM_CN_tot', 'Bcl-xl_100nM_isUnimodal', 'x100_p0',\n",
       "       'x100_p1', 'x100_p2', 'x100_p3', 'x100_p4', 'x100_p5', 'x100_p6',\n",
       "       'x100_p7', 'x100_p8', 'x100_p9', 'x100_p10', 'x100_p11',\n",
       "       'x100_expectedValue', 'x100_CN_0', 'x100_CN_1', 'x100_CN_2',\n",
       "       'x100_CN_3', 'x100_CN_4', 'x100_CN_5', 'x100_CN_6', 'x100_CN_7',\n",
       "       'x100_CN_8', 'x100_CN_9', 'x100_CN_10', 'x100_CN_11', 'x100_CN_tot',\n",
       "       'x100_isUnimodal', 'BCL-xl_1nM_p0', 'BCL-xl_1nM_p1',\n",
       "       'BCL-xl_1nM_p2', 'BCL-xl_1nM_p3', 'BCL-xl_1nM_p4', 'BCL-xl_1nM_p5',\n",
       "       'BCL-xl_1nM_p6', 'BCL-xl_1nM_p7', 'BCL-xl_1nM_p8', 'BCL-xl_1nM_p9',\n",
       "       'BCL-xl_1nM_p10', 'BCL-xl_1nM_p11', 'BCL-xl_1nM_expectedValue',\n",
       "       'BCL-xl_1nM_CN_0', 'BCL-xl_1nM_CN_1', 'BCL-xl_1nM_CN_2',\n",
       "       'BCL-xl_1nM_CN_3', 'BCL-xl_1nM_CN_4', 'BCL-xl_1nM_CN_5',\n",
       "       'BCL-xl_1nM_CN_6', 'BCL-xl_1nM_CN_7', 'BCL-xl_1nM_CN_8',\n",
       "       'BCL-xl_1nM_CN_9', 'BCL-xl_1nM_CN_10', 'BCL-xl_1nM_CN_11',\n",
       "       'BCL-xl_1nM_CN_tot', 'BCL-xl_1nM_isUnimodal', 'x1_p0', 'x1_p1',\n",
       "       'x1_p2', 'x1_p3', 'x1_p4', 'x1_p5', 'x1_p6', 'x1_p7', 'x1_p8',\n",
       "       'x1_p9', 'x1_p10', 'x1_p11', 'x1_expectedValue', 'x1_CN_0',\n",
       "       'x1_CN_1', 'x1_CN_2', 'x1_CN_3', 'x1_CN_4', 'x1_CN_5', 'x1_CN_6',\n",
       "       'x1_CN_7', 'x1_CN_8', 'x1_CN_9', 'x1_CN_10', 'x1_CN_11',\n",
       "       'x1_CN_tot', 'x1_isUnimodal', 'BFL1_100nM_p0', 'BFL1_100nM_p1',\n",
       "       'BFL1_100nM_p2', 'BFL1_100nM_p3', 'BFL1_100nM_p4', 'BFL1_100nM_p5',\n",
       "       'BFL1_100nM_p6', 'BFL1_100nM_p7', 'BFL1_100nM_p8', 'BFL1_100nM_p9',\n",
       "       'BFL1_100nM_p10', 'BFL1_100nM_p11', 'BFL1_100nM_expectedValue',\n",
       "       'BFL1_100nM_CN_0', 'BFL1_100nM_CN_1', 'BFL1_100nM_CN_2',\n",
       "       'BFL1_100nM_CN_3', 'BFL1_100nM_CN_4', 'BFL1_100nM_CN_5',\n",
       "       'BFL1_100nM_CN_6', 'BFL1_100nM_CN_7', 'BFL1_100nM_CN_8',\n",
       "       'BFL1_100nM_CN_9', 'BFL1_100nM_CN_10', 'BFL1_100nM_CN_11',\n",
       "       'BFL1_100nM_CN_tot', 'BFL1_100nM_isUnimodal', 'bfl1_p0', 'bfl1_p1',\n",
       "       'bfl1_p2', 'bfl1_p3', 'bfl1_p4', 'bfl1_p5', 'bfl1_p6', 'bfl1_p7',\n",
       "       'bfl1_p8', 'bfl1_p9', 'bfl1_p10', 'bfl1_p11', 'bfl1_expectedValue',\n",
       "       'bfl1_CN_0', 'bfl1_CN_1', 'bfl1_CN_2', 'bfl1_CN_3', 'bfl1_CN_4',\n",
       "       'bfl1_CN_5', 'bfl1_CN_6', 'bfl1_CN_7', 'bfl1_CN_8', 'bfl1_CN_9',\n",
       "       'bfl1_CN_10', 'bfl1_CN_11', 'bfl1_CN_tot', 'bfl1_isUnimodal'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allSeqs.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_b = \"GGCCGTCCG[ACG][AT][CG]ATTTGG[ACGT][AT]TGCGCAGGAACTG[AG][CGT]ACGT[ACGT][ACGT]CG[CG]CGATGAATTT[ACG][ACT]C[AG][AC]ATAT[ACGT][ACG]C\"\n",
    "m_b = \"GGCCGT[ACGT][CG]GGAA[CGT][ACGT]C[CG]A[AT][AG][CT]C[AG][CGT]TCAGGAACTG[AG][ACGT]ACGTATTGGCGATGAA[ACGT][ACT]T[ACG]A[GT]GCGTATTAT\"\n",
    "f_b = \"GGCCGTCCG[ACG][ACT]AATTTGGATT[GT][ACG]TCAG[ACGT][AGT]CCTGCGTCGT[ACGT][CGT]CGGCGAT[ACG][AT][GT][ACGT][ACT]TAATGCGTAT[ACGT][CT]T\"\n",
    "x_p = \"GGCCAATGG[ACG][AT][CG]CGTGAA[ACGT][AT]TGGCGCCCAACTG[AG][CGT]ACGC[ACGT][ACGT]CG[CG]CGATGATCTG[ACG][ACT]C[AG][AC]ACAA[ACGT][ACG]C\"\n",
    "m_p = \"GGCCAA[ACGT][CG]GGCG[CGT][ACGT]C[CG]A[AT][AG][CT]C[AG][CGT]TGCCCAACTG[AG][ACGT]ACGCATGGCGGATGAT[ACGT][ACT]T[ACG]A[GT]GCCCAATAT\"\n",
    "f_p = \"GGCCAATGG[ACG][ACT]ACGTGAAATT[GT][ACG]TGCC[ACGT][AGT]CCTGCGTCGC[ACGT][CGT]CGCGGAT[ACG][AT][GT][ACGT][ACT]TAATGCCCAA[ACGT][CT]T\"\n",
    "justinRegex =[x_b,m_b,f_b,x_p,m_p,f_p]\n",
    "\n",
    "def getLibrary(inputSeq):\n",
    "    label = ['x_b','m_b','f_b','x_p','m_p','f_p']\n",
    "    \n",
    "    matches = []\n",
    "    \n",
    "    for label,regx in zip(label,justinRegex):\n",
    "        if(re.match(regx,inputSeq)):\n",
    "            matches.append(label)\n",
    "    \n",
    "    if(len(matches)==0):\n",
    "        return \"unknown\"\n",
    "    return \",\".join(matches)\n",
    "\n",
    "allSeqs['source'] = allSeqs.apply(lambda x: getLibrary(x.seq),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allSeqs.to_pickle(\"/home/vxue/data/sort_specificity/intersectData_noFilter_outerjoin.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
