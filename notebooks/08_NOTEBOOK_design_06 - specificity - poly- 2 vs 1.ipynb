{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load /home/vxue/data/sort_specificity/design_y/scripts/final/poly_specificty_1v2.py\n",
    "\n",
    "\n",
    "from pulp import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "aminoAcidIndex = 'ACEDGFIHKMLNQPSRTWVY'\n",
    "myPosLabels=['1E','1F','1G','2A','2B','2C','2D','2E','2F','2G','3A','3B','3C','3D','3E','3F','3G','4A','4B','4C','4D','4E']\n",
    "\n",
    "\n",
    "def kcalToKD(i):\n",
    "    return np.e**(i/ ((1.9872041 * 10**-3)  * (298))) * 10**9\n",
    "\n",
    "###############################\n",
    "# Define ILP Functions to generate constraints\n",
    "###############################\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addLinearConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    \n",
    "    allSingleAAConstraints = []\n",
    "    \n",
    "    for i in range(numAA):\n",
    "        #blank = np.zeros(int((numAA*20)+((numAA*20)*((numAA*20)+1)/2)))\n",
    "        prob+=lpSum(allVariables[i*20+j+offset] for j in range(20)) == 1\n",
    "    \n",
    "\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addPairConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    signs = [1,-1]        \n",
    "    arrayOffset = numAA*20\n",
    "    arrayDim = numAA*20\n",
    "    #Expanded Vector1\n",
    "    for i in range(numAA*20):\n",
    "        ##################################################\n",
    "        tempArray=[]\n",
    "        #Expanded Vector2        \n",
    "        for j in range(i,numAA*20):\n",
    "\n",
    "            if(j%20==0 and j!=i): # For each set of 20, add another constraint\n",
    "                \n",
    "                tempArray.append((allVariables[i+offset],-1)) # AA constraint for single term\n",
    "                prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "                tempArray=[]\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "            else:\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "\n",
    "        \n",
    "            arrayOffset+=1\n",
    "            \n",
    "        tempArray.append((allVariables[i+offset],-1))   \n",
    "        prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "        ##################################################\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Second Set of constraints to assure second variable is stable\n",
    "        #################################################\n",
    "        \n",
    "        \n",
    "        tempArray2=[]\n",
    "        #print(allVariables[i+offset], \"=============\", i)\n",
    "        \n",
    "        for k in range(i+1): # k is the number of times to add pair terms\n",
    "            \n",
    "            if(k>1 and k%20==0): #every 20, add another constraint that at most one pair can be selected\n",
    "                \n",
    "                # Assert that feature occurs as singleton\n",
    "                tempArray2.append((allVariables[i+offset],-1))  \n",
    "                prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "                tempArray2=[]\n",
    "            \n",
    "\n",
    "            tempArray2.append((allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],1))\n",
    "            #These calculations help get the index of the next pair term \n",
    "            \n",
    "        \n",
    "            #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],end=\" \")\n",
    " \n",
    "        \n",
    "        #When complete, top it off and add the last set of constraints\n",
    "        tempArray2.append((allVariables[i+offset],-1))\n",
    "        #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],k,end=\" \")\n",
    "        prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "        \n",
    "        \n",
    "def getPolyExpansionLabels(inputVector):\n",
    "    \n",
    "    myLabels = []\n",
    "    \n",
    "\n",
    "    myDegree = 2\n",
    "    myNewVector=[]\n",
    "    \n",
    "    myLabels.append('Offset')\n",
    "    for idx,each in enumerate(inputVector):\n",
    "        myNewVector.append(np.sqrt(2)*each)\n",
    "        myLabels.append(myPosLabels[idx//20]+\"_\"+aminoAcidIndex[idx%20])\n",
    "    \n",
    "    for i in range(len(inputVector)):\n",
    "        for j in range(i,len(inputVector)):\n",
    "            \n",
    "            myLabels.append(myPosLabels[i//20]+\"_\"+aminoAcidIndex[i%20]+\"__\"+\n",
    "            myPosLabels[j//20]+\"_\"+aminoAcidIndex[j%20])\n",
    "    \n",
    "    return myLabels\n",
    "\n",
    "def getK(dim,iteration):\n",
    "    mySum = 0\n",
    "    for i in range(1,iteration+1):\n",
    "        mySum+= (dim-i)\n",
    "    return mySum\n",
    "\n",
    "###############################\n",
    "# Define Dummy Variable Encoding\n",
    "###############################\n",
    "\n",
    "def getAAVector(letter):\n",
    "    vector = np.zeros(20);\n",
    "    vector[aminoAcidIndex.index(letter)]=1\n",
    "    return  vector\n",
    "\n",
    "def encodeWithDummyVariables(sequence):\n",
    "    newArray=[]\n",
    "    for aa in sequence:\n",
    "        newArray.append(getAAVector(aa))\n",
    "    return np.array(newArray).ravel()\n",
    "\n",
    "\n",
    "def addLinearConstraint_Forbiden(prob,allVariables,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bim):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "        \n",
    "    for idx,each in enumerate(puma):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mixMut):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "    \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<25:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    disallowed = (~allowedArray.astype(bool)).astype(int)\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(disallowed):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "    \n",
    "    return allowedArray\n",
    "\n",
    "#############################\n",
    "# Define Library Constraints\n",
    "#############################\n",
    "\n",
    "bim = 'GRPEIWIAQELRRIGDEFNAYY'\n",
    "puma = 'GQWAREIGAQLRRMADDLNAQY'\n",
    "xMut = ['']*22\n",
    "xMut[3] = 'DEHIKLMNQV'\n",
    "xMut[6] ='DFHILNVY'\n",
    "xMut[11]='AGIRTV'\n",
    "xMut[13]='ADFGHILNPRSTVY' #C\n",
    "xMut[14]='AG'\n",
    "xMut[18]='ADHILNPTV'\n",
    "xMut[19]='AEKT'\n",
    "xMut[21]='ADGHNPRSTY' #C\n",
    "\n",
    "mMut = ['']*22\n",
    "mMut[2] = 'AGPRSTW'\n",
    "mMut[4]='ADFGHLPRSVY' #C\n",
    "mMut[5]='DEHQ'\n",
    "mMut[6]='AITV'\n",
    "mMut[7]='AGISTV'\n",
    "mMut[11]='AEGIKRTV'\n",
    "mMut[17]='ADFHILNPSTVY'\n",
    "mMut[18]='DEHKNQ'\n",
    "\n",
    "fMut = ['']*22\n",
    "fMut[3] = 'AEIKLPQTV'\n",
    "fMut[7]='ADGSY' #C\n",
    "fMut[9]='DFGHILNRSVY'# C\n",
    "fMut[13]='AFGILPRSTV' #C\n",
    "fMut[16]='DEHIKLMNQV'\n",
    "fMut[17]='ADFHILNPSTVY'\n",
    "fMut[21]='AFILPSTV'\n",
    "\n",
    "mixMut = []\n",
    "for i in range(22):\n",
    "    mixMut.append(set(xMut[i]).union(set(mMut[i])).union(set(fMut[i])))\n",
    "\n",
    "libVariables = [LpVariable(\"i_\"+j,0,22,LpInteger) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "libVariablesBinary = [LpVariable(\"b_\"+j,0,22,LpBinary) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "\n",
    "\n",
    "\n",
    "def addLinearConstraintSingleLib(prob,allVariables,bgLib,mutAllowed,libVar,libVarBin,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bgLib):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mutAllowed):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "            \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<10:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(allowedArray):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == libVar\n",
    "    prob += libVar >= libVarBin*22 # libVarBin is 1 if libVar is >= 22\n",
    "    #Because of the other constraints - this is just a variable that assigns boolean == 22\n",
    "    \n",
    "    return tempArray\n",
    "    \n",
    "def addLinearConstraintMultipleLib(prob,allVariables,offset=1):\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,xMut,libVariables[0],libVariablesBinary[0],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,mMut,libVariables[1],libVariablesBinary[1],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,fMut,libVariables[2],libVariablesBinary[2],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,xMut,libVariables[3],libVariablesBinary[3],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,mMut,libVariables[4],libVariablesBinary[4],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,fMut,libVariables[5],libVariablesBinary[5],offset)\n",
    "def addLinearConstraint_library(prob,allVariables,offset=1):\n",
    "    prob+= lpSum(each for each in libVariablesBinary) >= 1\n",
    "    addLinearConstraintMultipleLib(prob,allVariables,offset)\n",
    "    #print(libVariables)\n",
    "\n",
    "    \n",
    "#############################\n",
    "# Start loading model specific reqs\n",
    "#############################\n",
    "\n",
    "allData,allDataName = pickle.load(open('/home/vxue/data/sort_specificity/ncv_y/allData.pickle','rb'))\n",
    "\n",
    "modelIndex = [allDataName.index(i) for i in ['all_x','all_s',\n",
    "                                             'all_m','all_n',\n",
    "                                             'all_f','all_t',\n",
    "                                             'all_z','all_c']]\n",
    "\n",
    "myIndex = [row+'_'+letter for row in myPosLabels for letter in aminoAcidIndex]\n",
    "\n",
    "myCounts = dict()\n",
    "for each,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myCounts[name]=posAA_toCount\n",
    "\n",
    "\n",
    "designsTargets = [  #Do the pairs by the ones that have the best cross validated performance\n",
    "    ('x','fn'),\n",
    "    ('f','nx'),\n",
    "    ('n','xf')]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "slurmInput = int(sys.argv[1])    \n",
    "\n",
    "cplexSolver = solvers.CPLEX_CMD(\"/scratch/users/mit_keating/Applications/CPLEX_Studio1271/cplex/bin/x86-64_linux/cplex\")\n",
    "\n",
    "\n",
    "for receptor1,receptor2 in [designsTargets[slurmInput]]:\n",
    "    \n",
    "    with open(\"/home/vxue/data/sort_specificity/design_y/specificity/trial1/\"+receptor1+\"-\"+receptor2+\"_poly.csv\",'w') as outFile:\n",
    "\n",
    "        model1 = \"all_\"+receptor1\n",
    "        model2 = \"all_\"+receptor2[0]\n",
    "        model3 = \"all_\"+receptor2[1]\n",
    "\n",
    "        print(model1,model2,model3)\n",
    "        aaCounts1  = [myCounts[model1][i] for i in myIndex]\n",
    "        aaCounts2  = [myCounts[model2][i] for i in myIndex]\n",
    "        aaCounts3  = [myCounts[model3][i] for i in myIndex]\n",
    "        aaCounts = min(aaCounts1,aaCounts2,aaCounts3)\n",
    "\n",
    "\n",
    "        featureTable = getPolyExpansionLabels(np.ones(440))\n",
    "        allVariables=[LpVariable(\"x_\"+j,0,1,LpBinary) for j in featureTable]\n",
    "\n",
    "        polyModel1 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model1+\".pickle\",'rb'))\n",
    "        weights1 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model1+\".weights\",'rb'))\n",
    "        polyModel2 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model2+\".pickle\",'rb'))\n",
    "        weights2 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model2+\".weights\",'rb'))\n",
    "        polyModel3 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model3+\".pickle\",'rb'))\n",
    "        weights3 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model3+\".weights\",'rb'))\n",
    "\n",
    "        weights =  weights1 # Go for affinity with constraints on the affinity of the other 2\n",
    "        weights[0] = 1 # Don't include the offset...\n",
    "\n",
    "\n",
    "\n",
    "        # defines the problem\n",
    "        prob = LpProblem(\"problem\", LpMinimize)\n",
    "        addLinearConstraint_Forbiden(prob,allVariables)\n",
    "        addLinearConstraintsPulp(22,prob,allVariables)\n",
    "        addPairConstraintsPulp(22,prob,allVariables)\n",
    "\n",
    "\n",
    "        #-10.9085 | -8.5 were the original constriants - but it is hard to find examples that meet his for x-fn\n",
    "        \n",
    "        #Affinity for target must be tighter than \n",
    "        prob += LpAffineExpression((allVariables[k],weights1[k]) for k in range(len(allVariables))) <= -10.9085  -polyModel1.intercept_[0]\n",
    "        #Affinity for offtarget must be less than \n",
    "        prob += LpAffineExpression((allVariables[k],weights2[k]) for k in range(len(allVariables))) >= -9.5 -polyModel2.intercept_[0]\n",
    "        prob += LpAffineExpression((allVariables[k],weights3[k]) for k in range(len(allVariables))) >= -9.5 -polyModel3.intercept_[0]\n",
    "\n",
    "\n",
    "        #Problem to Solve For\n",
    "        prob += LpAffineExpression((allVariables[k],weights[k]) for k in range(len(allVariables)))\n",
    "\n",
    "\n",
    "        topX = []\n",
    "        for iteration in range(200):\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            status = prob.solve(cplexSolver)\n",
    "            LpStatus[status]\n",
    "\n",
    "            if(LpStatus[status]=='Optimal'):\n",
    "                \n",
    "            \n",
    "                allValues = [(idx,i,value(i)) for idx,i in enumerate(allVariables) if np.abs(value(i))>10**-6]\n",
    "                optSeq = \"\".join([str(allValues[i][1])[5:] for i in range(0,22)])\n",
    "\n",
    "                prob+= lpSum([allVariables[allValues[i][0]] for i in range(22)]) <= 21\n",
    "\n",
    "\n",
    "\n",
    "                #optSeq = receptor1+\"_\"+receptor2+str(iteration)\n",
    "\n",
    "                topX.append(optSeq)\n",
    "\n",
    "                #optSeqScore1 = polyModel1.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                #optSeqScore2 = polyModel2.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                #optSeqScore3 = polyModel3.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "\n",
    "                outFile.write(topX[-1])\n",
    "                outFile.write(\"\\n\")\n",
    "                outFile.flush()\n",
    "            else:\n",
    "                outFile.write(LpStatus[status])\n",
    "                outFile.flush()\n",
    "\n",
    "                break\n",
    "                \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /home/vxue/data/sort_specificity/design_y/scripts/final/poly_specificty_2v1.py\n",
    "\n",
    "\n",
    "from pulp import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "aminoAcidIndex = 'ACEDGFIHKMLNQPSRTWVY'\n",
    "myPosLabels=['1E','1F','1G','2A','2B','2C','2D','2E','2F','2G','3A','3B','3C','3D','3E','3F','3G','4A','4B','4C','4D','4E']\n",
    "\n",
    "\n",
    "def kcalToKD(i):\n",
    "    return np.e**(i/ ((1.9872041 * 10**-3)  * (298))) * 10**9\n",
    "\n",
    "###############################\n",
    "# Define ILP Functions to generate constraints\n",
    "###############################\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addLinearConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    \n",
    "    allSingleAAConstraints = []\n",
    "    \n",
    "    for i in range(numAA):\n",
    "        #blank = np.zeros(int((numAA*20)+((numAA*20)*((numAA*20)+1)/2)))\n",
    "        prob+=lpSum(allVariables[i*20+j+offset] for j in range(20)) == 1\n",
    "    \n",
    "\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addPairConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    signs = [1,-1]        \n",
    "    arrayOffset = numAA*20\n",
    "    arrayDim = numAA*20\n",
    "    #Expanded Vector1\n",
    "    for i in range(numAA*20):\n",
    "        ##################################################\n",
    "        tempArray=[]\n",
    "        #Expanded Vector2        \n",
    "        for j in range(i,numAA*20):\n",
    "\n",
    "            if(j%20==0 and j!=i): # For each set of 20, add another constraint\n",
    "                \n",
    "                tempArray.append((allVariables[i+offset],-1)) # AA constraint for single term\n",
    "                prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "                tempArray=[]\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "            else:\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "\n",
    "        \n",
    "            arrayOffset+=1\n",
    "            \n",
    "        tempArray.append((allVariables[i+offset],-1))   \n",
    "        prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "        ##################################################\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Second Set of constraints to assure second variable is stable\n",
    "        #################################################\n",
    "        \n",
    "        \n",
    "        tempArray2=[]\n",
    "        #print(allVariables[i+offset], \"=============\", i)\n",
    "        \n",
    "        for k in range(i+1): # k is the number of times to add pair terms\n",
    "            \n",
    "            if(k>1 and k%20==0): #every 20, add another constraint that at most one pair can be selected\n",
    "                \n",
    "                # Assert that feature occurs as singleton\n",
    "                tempArray2.append((allVariables[i+offset],-1))  \n",
    "                prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "                tempArray2=[]\n",
    "            \n",
    "\n",
    "            tempArray2.append((allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],1))\n",
    "            #These calculations help get the index of the next pair term \n",
    "            \n",
    "        \n",
    "            #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],end=\" \")\n",
    " \n",
    "        \n",
    "        #When complete, top it off and add the last set of constraints\n",
    "        tempArray2.append((allVariables[i+offset],-1))\n",
    "        #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],k,end=\" \")\n",
    "        prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "        \n",
    "        \n",
    "def getPolyExpansionLabels(inputVector):\n",
    "    \n",
    "    myLabels = []\n",
    "    \n",
    "\n",
    "    myDegree = 2\n",
    "    myNewVector=[]\n",
    "    \n",
    "    myLabels.append('Offset')\n",
    "    for idx,each in enumerate(inputVector):\n",
    "        myNewVector.append(np.sqrt(2)*each)\n",
    "        myLabels.append(myPosLabels[idx//20]+\"_\"+aminoAcidIndex[idx%20])\n",
    "    \n",
    "    for i in range(len(inputVector)):\n",
    "        for j in range(i,len(inputVector)):\n",
    "            \n",
    "            myLabels.append(myPosLabels[i//20]+\"_\"+aminoAcidIndex[i%20]+\"__\"+\n",
    "            myPosLabels[j//20]+\"_\"+aminoAcidIndex[j%20])\n",
    "    \n",
    "    return myLabels\n",
    "\n",
    "def getK(dim,iteration):\n",
    "    mySum = 0\n",
    "    for i in range(1,iteration+1):\n",
    "        mySum+= (dim-i)\n",
    "    return mySum\n",
    "\n",
    "###############################\n",
    "# Define Dummy Variable Encoding\n",
    "###############################\n",
    "\n",
    "def getAAVector(letter):\n",
    "    vector = np.zeros(20);\n",
    "    vector[aminoAcidIndex.index(letter)]=1\n",
    "    return  vector\n",
    "\n",
    "def encodeWithDummyVariables(sequence):\n",
    "    newArray=[]\n",
    "    for aa in sequence:\n",
    "        newArray.append(getAAVector(aa))\n",
    "    return np.array(newArray).ravel()\n",
    "\n",
    "\n",
    "def addLinearConstraint_Forbiden(prob,allVariables,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bim):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "        \n",
    "    for idx,each in enumerate(puma):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mixMut):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "    \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<25:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    disallowed = (~allowedArray.astype(bool)).astype(int)\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(disallowed):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "    \n",
    "    return allowedArray\n",
    "\n",
    "#############################\n",
    "# Define Library Constraints\n",
    "#############################\n",
    "\n",
    "bim = 'GRPEIWIAQELRRIGDEFNAYY'\n",
    "puma = 'GQWAREIGAQLRRMADDLNAQY'\n",
    "xMut = ['']*22\n",
    "xMut[3] = 'DEHIKLMNQV'\n",
    "xMut[6] ='DFHILNVY'\n",
    "xMut[11]='AGIRTV'\n",
    "xMut[13]='ADFGHILNPRSTVY' #C\n",
    "xMut[14]='AG'\n",
    "xMut[18]='ADHILNPTV'\n",
    "xMut[19]='AEKT'\n",
    "xMut[21]='ADGHNPRSTY' #C\n",
    "\n",
    "mMut = ['']*22\n",
    "mMut[2] = 'AGPRSTW'\n",
    "mMut[4]='ADFGHLPRSVY' #C\n",
    "mMut[5]='DEHQ'\n",
    "mMut[6]='AITV'\n",
    "mMut[7]='AGISTV'\n",
    "mMut[11]='AEGIKRTV'\n",
    "mMut[17]='ADFHILNPSTVY'\n",
    "mMut[18]='DEHKNQ'\n",
    "\n",
    "fMut = ['']*22\n",
    "fMut[3] = 'AEIKLPQTV'\n",
    "fMut[7]='ADGSY' #C\n",
    "fMut[9]='DFGHILNRSVY'# C\n",
    "fMut[13]='AFGILPRSTV' #C\n",
    "fMut[16]='DEHIKLMNQV'\n",
    "fMut[17]='ADFHILNPSTVY'\n",
    "fMut[21]='AFILPSTV'\n",
    "\n",
    "mixMut = []\n",
    "for i in range(22):\n",
    "    mixMut.append(set(xMut[i]).union(set(mMut[i])).union(set(fMut[i])))\n",
    "\n",
    "libVariables = [LpVariable(\"i_\"+j,0,22,LpInteger) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "libVariablesBinary = [LpVariable(\"b_\"+j,0,22,LpBinary) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "\n",
    "\n",
    "\n",
    "def addLinearConstraintSingleLib(prob,allVariables,bgLib,mutAllowed,libVar,libVarBin,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bgLib):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mutAllowed):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "            \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<10:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(allowedArray):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == libVar\n",
    "    prob += libVar >= libVarBin*22 # libVarBin is 1 if libVar is >= 22\n",
    "    #Because of the other constraints - this is just a variable that assigns boolean == 22\n",
    "    \n",
    "    return tempArray\n",
    "    \n",
    "def addLinearConstraintMultipleLib(prob,allVariables,offset=1):\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,xMut,libVariables[0],libVariablesBinary[0],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,mMut,libVariables[1],libVariablesBinary[1],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,fMut,libVariables[2],libVariablesBinary[2],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,xMut,libVariables[3],libVariablesBinary[3],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,mMut,libVariables[4],libVariablesBinary[4],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,fMut,libVariables[5],libVariablesBinary[5],offset)\n",
    "def addLinearConstraint_library(prob,allVariables,offset=1):\n",
    "    prob+= lpSum(each for each in libVariablesBinary) >= 1\n",
    "    addLinearConstraintMultipleLib(prob,allVariables,offset)\n",
    "    #print(libVariables)\n",
    "\n",
    "    \n",
    "#############################\n",
    "# Start loading model specific reqs\n",
    "#############################\n",
    "\n",
    "allData,allDataName = pickle.load(open('/home/vxue/data/sort_specificity/ncv_y/allData.pickle','rb'))\n",
    "\n",
    "modelIndex = [allDataName.index(i) for i in ['all_x','all_s',\n",
    "                                             'all_m','all_n',\n",
    "                                             'all_f','all_t',\n",
    "                                             'all_z','all_c']]\n",
    "\n",
    "myIndex = [row+'_'+letter for row in myPosLabels for letter in aminoAcidIndex]\n",
    "\n",
    "myCounts = dict()\n",
    "for each,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myCounts[name]=posAA_toCount\n",
    "\n",
    "\n",
    "designsTargets = [  #Do the pairs by the ones that have the best cross validated performance\n",
    "    ('fn','x'),\n",
    "    ('nx','f'),\n",
    "    ('xf','n')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "slurmInput = int(sys.argv[1])    \n",
    "\n",
    "\n",
    "cplexSolver = solvers.CPLEX_CMD(\"/scratch/users/mit_keating/Applications/CPLEX_Studio1271/cplex/bin/x86-64_linux/cplex\")\n",
    "\n",
    "for receptor1,receptor2 in [designsTargets[slurmInput]]:\n",
    "    \n",
    "    with open(\"/home/vxue/data/sort_specificity/design_y/specificity/trial3/\"+receptor1+\"-\"+receptor2+\"_poly.csv\",'w') as outFile:\n",
    "\n",
    "        model1 = \"all_\"+receptor1[0]\n",
    "        model2 = \"all_\"+receptor1[1]\n",
    "        model3 = \"all_\"+receptor2\n",
    "\n",
    "\n",
    "        print(model1,model2,model3)\n",
    "        aaCounts1  = [myCounts[model1][i] for i in myIndex]\n",
    "        aaCounts2  = [myCounts[model2][i] for i in myIndex]\n",
    "        aaCounts3  = [myCounts[model3][i] for i in myIndex]\n",
    "        aaCounts = min(aaCounts1,aaCounts2,aaCounts3)\n",
    "\n",
    "\n",
    "        featureTable = getPolyExpansionLabels(np.ones(440))\n",
    "        allVariables=[LpVariable(\"x_\"+j,0,1,LpBinary) for j in featureTable]\n",
    "\n",
    "        polyModel1 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model1+\".pickle\",'rb'))\n",
    "        weights1 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model1+\".weights\",'rb'))\n",
    "        polyModel2 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model2+\".pickle\",'rb'))\n",
    "        weights2 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model2+\".weights\",'rb'))\n",
    "        polyModel3 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model3+\".pickle\",'rb'))\n",
    "        weights3 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model3+\".weights\",'rb'))\n",
    "\n",
    "        weights =  weights3 # Go for the most destabilizing off target\n",
    "        weights[0] = -1 # Don't include the offset...\n",
    "\n",
    "\n",
    "\n",
    "        # defines the problem\n",
    "        prob = LpProblem(\"problem\", LpMaximize) #########<<<<<<<<<<<<<<<<<<<<< MAXIMIZE\n",
    "        addLinearConstraint_Forbiden(prob,allVariables)\n",
    "        addLinearConstraintsPulp(22,prob,allVariables)\n",
    "        addPairConstraintsPulp(22,prob,allVariables)\n",
    "\n",
    "\n",
    "        #Affinity for target must be tighter than \n",
    "        prob += LpAffineExpression((allVariables[k],weights1[k]) for k in range(len(allVariables))) <= -10 -polyModel1.intercept_[0]\n",
    "        prob += LpAffineExpression((allVariables[k],weights2[k]) for k in range(len(allVariables))) <= -10 -polyModel2.intercept_[0]\n",
    "        #Affinity for offtarget must be less than \n",
    "        prob += LpAffineExpression((allVariables[k],weights3[k]) for k in range(len(allVariables))) >= -8.5 -polyModel3.intercept_[0]\n",
    "\n",
    "\n",
    "        #Problem to Solve For\n",
    "        prob += LpAffineExpression((allVariables[k],weights[k]) for k in range(len(allVariables)))\n",
    "\n",
    "\n",
    "        topX = []\n",
    "        for iteration in range(1000):\n",
    "            \n",
    "            status = prob.solve(cplexSolver)\n",
    "            LpStatus[status]\n",
    "            \n",
    "            if(LpStatus[status]=='Optimal'):                \n",
    "\n",
    "                allValues = [(idx,i,value(i)) for idx,i in enumerate(allVariables) if np.abs(value(i))>10**-6]\n",
    "                optSeq = \"\".join([str(allValues[i][1])[5:] for i in range(0,22)])\n",
    "\n",
    "                prob+= lpSum([allVariables[allValues[i][0]] for i in range(22)]) <= 21\n",
    "\n",
    "\n",
    "\n",
    "                #optSeq = receptor1+\"_\"+receptor2+str(iteration)\n",
    "\n",
    "                topX.append(optSeq)\n",
    "\n",
    "                #optSeqScore1 = polyModel1.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                #optSeqScore2 = polyModel2.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                #optSeqScore3 = polyModel3.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "\n",
    "                outFile.write(topX[-1])\n",
    "                outFile.write(\"\\n\")\n",
    "                outFile.flush()\n",
    "            else:\n",
    "                outFile.write(LpStatus[status])\n",
    "                outFile.flush()\n",
    "                break\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /home/vxue/data/sort_specificity/design_y/scripts/final/poly_specificty_2v1_edge.py\n",
    "\n",
    "\n",
    "from pulp import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "aminoAcidIndex = 'ACEDGFIHKMLNQPSRTWVY'\n",
    "myPosLabels=['1E','1F','1G','2A','2B','2C','2D','2E','2F','2G','3A','3B','3C','3D','3E','3F','3G','4A','4B','4C','4D','4E']\n",
    "\n",
    "\n",
    "def kcalToKD(i):\n",
    "    return np.e**(i/ ((1.9872041 * 10**-3)  * (298))) * 10**9\n",
    "\n",
    "###############################\n",
    "# Define ILP Functions to generate constraints\n",
    "###############################\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addLinearConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    \n",
    "    allSingleAAConstraints = []\n",
    "    \n",
    "    for i in range(numAA):\n",
    "        #blank = np.zeros(int((numAA*20)+((numAA*20)*((numAA*20)+1)/2)))\n",
    "        prob+=lpSum(allVariables[i*20+j+offset] for j in range(20)) == 1\n",
    "    \n",
    "\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addPairConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    signs = [1,-1]        \n",
    "    arrayOffset = numAA*20\n",
    "    arrayDim = numAA*20\n",
    "    #Expanded Vector1\n",
    "    for i in range(numAA*20):\n",
    "        ##################################################\n",
    "        tempArray=[]\n",
    "        #Expanded Vector2        \n",
    "        for j in range(i,numAA*20):\n",
    "\n",
    "            if(j%20==0 and j!=i): # For each set of 20, add another constraint\n",
    "                \n",
    "                tempArray.append((allVariables[i+offset],-1)) # AA constraint for single term\n",
    "                prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "                tempArray=[]\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "            else:\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "\n",
    "        \n",
    "            arrayOffset+=1\n",
    "            \n",
    "        tempArray.append((allVariables[i+offset],-1))   \n",
    "        prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "        ##################################################\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Second Set of constraints to assure second variable is stable\n",
    "        #################################################\n",
    "        \n",
    "        \n",
    "        tempArray2=[]\n",
    "        #print(allVariables[i+offset], \"=============\", i)\n",
    "        \n",
    "        for k in range(i+1): # k is the number of times to add pair terms\n",
    "            \n",
    "            if(k>1 and k%20==0): #every 20, add another constraint that at most one pair can be selected\n",
    "                \n",
    "                # Assert that feature occurs as singleton\n",
    "                tempArray2.append((allVariables[i+offset],-1))  \n",
    "                prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "                tempArray2=[]\n",
    "            \n",
    "\n",
    "            tempArray2.append((allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],1))\n",
    "            #These calculations help get the index of the next pair term \n",
    "            \n",
    "        \n",
    "            #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],end=\" \")\n",
    " \n",
    "        \n",
    "        #When complete, top it off and add the last set of constraints\n",
    "        tempArray2.append((allVariables[i+offset],-1))\n",
    "        #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],k,end=\" \")\n",
    "        prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "        \n",
    "        \n",
    "def getPolyExpansionLabels(inputVector):\n",
    "    \n",
    "    myLabels = []\n",
    "    \n",
    "\n",
    "    myDegree = 2\n",
    "    myNewVector=[]\n",
    "    \n",
    "    myLabels.append('Offset')\n",
    "    for idx,each in enumerate(inputVector):\n",
    "        myNewVector.append(np.sqrt(2)*each)\n",
    "        myLabels.append(myPosLabels[idx//20]+\"_\"+aminoAcidIndex[idx%20])\n",
    "    \n",
    "    for i in range(len(inputVector)):\n",
    "        for j in range(i,len(inputVector)):\n",
    "            \n",
    "            myLabels.append(myPosLabels[i//20]+\"_\"+aminoAcidIndex[i%20]+\"__\"+\n",
    "            myPosLabels[j//20]+\"_\"+aminoAcidIndex[j%20])\n",
    "    \n",
    "    return myLabels\n",
    "\n",
    "def getK(dim,iteration):\n",
    "    mySum = 0\n",
    "    for i in range(1,iteration+1):\n",
    "        mySum+= (dim-i)\n",
    "    return mySum\n",
    "\n",
    "###############################\n",
    "# Define Dummy Variable Encoding\n",
    "###############################\n",
    "\n",
    "def getAAVector(letter):\n",
    "    vector = np.zeros(20);\n",
    "    vector[aminoAcidIndex.index(letter)]=1\n",
    "    return  vector\n",
    "\n",
    "def encodeWithDummyVariables(sequence):\n",
    "    newArray=[]\n",
    "    for aa in sequence:\n",
    "        newArray.append(getAAVector(aa))\n",
    "    return np.array(newArray).ravel()\n",
    "\n",
    "\n",
    "def addLinearConstraint_Forbiden(prob,allVariables,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bim):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "        \n",
    "    for idx,each in enumerate(puma):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mixMut):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "    \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<25:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    disallowed = (~allowedArray.astype(bool)).astype(int)\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(disallowed):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "    \n",
    "    return allowedArray\n",
    "\n",
    "#############################\n",
    "# Define Library Constraints\n",
    "#############################\n",
    "\n",
    "bim = 'GRPEIWIAQELRRIGDEFNAYY'\n",
    "puma = 'GQWAREIGAQLRRMADDLNAQY'\n",
    "xMut = ['']*22\n",
    "xMut[3] = 'DEHIKLMNQV'\n",
    "xMut[6] ='DFHILNVY'\n",
    "xMut[11]='AGIRTV'\n",
    "xMut[13]='ADFGHILNPRSTVY' #C\n",
    "xMut[14]='AG'\n",
    "xMut[18]='ADHILNPTV'\n",
    "xMut[19]='AEKT'\n",
    "xMut[21]='ADGHNPRSTY' #C\n",
    "\n",
    "mMut = ['']*22\n",
    "mMut[2] = 'AGPRSTW'\n",
    "mMut[4]='ADFGHLPRSVY' #C\n",
    "mMut[5]='DEHQ'\n",
    "mMut[6]='AITV'\n",
    "mMut[7]='AGISTV'\n",
    "mMut[11]='AEGIKRTV'\n",
    "mMut[17]='ADFHILNPSTVY'\n",
    "mMut[18]='DEHKNQ'\n",
    "\n",
    "fMut = ['']*22\n",
    "fMut[3] = 'AEIKLPQTV'\n",
    "fMut[7]='ADGSY' #C\n",
    "fMut[9]='DFGHILNRSVY'# C\n",
    "fMut[13]='AFGILPRSTV' #C\n",
    "fMut[16]='DEHIKLMNQV'\n",
    "fMut[17]='ADFHILNPSTVY'\n",
    "fMut[21]='AFILPSTV'\n",
    "\n",
    "mixMut = []\n",
    "for i in range(22):\n",
    "    mixMut.append(set(xMut[i]).union(set(mMut[i])).union(set(fMut[i])))\n",
    "\n",
    "libVariables = [LpVariable(\"i_\"+j,0,22,LpInteger) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "libVariablesBinary = [LpVariable(\"b_\"+j,0,22,LpBinary) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "\n",
    "\n",
    "\n",
    "def addLinearConstraintSingleLib(prob,allVariables,bgLib,mutAllowed,libVar,libVarBin,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bgLib):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mutAllowed):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "            \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<10:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(allowedArray):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == libVar\n",
    "    prob += libVar >= libVarBin*22 # libVarBin is 1 if libVar is >= 22\n",
    "    #Because of the other constraints - this is just a variable that assigns boolean == 22\n",
    "    \n",
    "    return tempArray\n",
    "    \n",
    "def addLinearConstraintMultipleLib(prob,allVariables,offset=1):\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,xMut,libVariables[0],libVariablesBinary[0],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,mMut,libVariables[1],libVariablesBinary[1],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,fMut,libVariables[2],libVariablesBinary[2],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,xMut,libVariables[3],libVariablesBinary[3],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,mMut,libVariables[4],libVariablesBinary[4],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,fMut,libVariables[5],libVariablesBinary[5],offset)\n",
    "def addLinearConstraint_library(prob,allVariables,offset=1):\n",
    "    prob+= lpSum(each for each in libVariablesBinary) >= 1\n",
    "    addLinearConstraintMultipleLib(prob,allVariables,offset)\n",
    "    #print(libVariables)\n",
    "\n",
    "    \n",
    "#############################\n",
    "# Start loading model specific reqs\n",
    "#############################\n",
    "\n",
    "allData,allDataName = pickle.load(open('/home/vxue/data/sort_specificity/ncv_y/allData.pickle','rb'))\n",
    "\n",
    "modelIndex = [allDataName.index(i) for i in ['all_x','all_s',\n",
    "                                             'all_m','all_n',\n",
    "                                             'all_f','all_t',\n",
    "                                             'all_z','all_c']]\n",
    "\n",
    "myIndex = [row+'_'+letter for row in myPosLabels for letter in aminoAcidIndex]\n",
    "\n",
    "myCounts = dict()\n",
    "for each,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myCounts[name]=posAA_toCount\n",
    "\n",
    "\n",
    "designsTargets = [  #Do the pairs by the ones that have the best cross validated performance\n",
    "    ('fn','x'),\n",
    "    ('nx','f'),\n",
    "    ('xf','n')]\n",
    "\n",
    "slurmInput =int(sys.argv[1])    \n",
    "\n",
    "\n",
    "cplexSolver = solvers.CPLEX_CMD(\"/scratch/users/mit_keating/Applications/CPLEX_Studio1271/cplex/bin/x86-64_linux/cplex\")\n",
    "\n",
    "for receptor1,receptor2 in [designsTargets[slurmInput]]:\n",
    "    \n",
    "    with open(\"/home/vxue/data/sort_specificity/design_y/specificity/trial5/\"+receptor1+\"-\"+receptor2+\"_poly.csv\",'w') as outFile:\n",
    "        model1 = \"all_\"+receptor1[0]\n",
    "        model2 = \"all_\"+receptor1[1]\n",
    "        model3 = \"all_\"+receptor2\n",
    "\n",
    "\n",
    "        print(model1,model2,model3)\n",
    "        aaCounts1  = [myCounts[model1][i] for i in myIndex]\n",
    "        aaCounts2  = [myCounts[model2][i] for i in myIndex]\n",
    "        aaCounts3  = [myCounts[model3][i] for i in myIndex]\n",
    "        aaCounts = min(aaCounts1,aaCounts2,aaCounts3)\n",
    "\n",
    "\n",
    "        featureTable = getPolyExpansionLabels(np.ones(440))\n",
    "        allVariables=[LpVariable(\"x_\"+j,0,1,LpBinary) for j in featureTable]\n",
    "\n",
    "        polyModel1 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model1+\".pickle\",'rb'))\n",
    "        weights1 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model1+\".weights\",'rb'))\n",
    "        polyModel2 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model2+\".pickle\",'rb'))\n",
    "        weights2 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model2+\".weights\",'rb'))\n",
    "        polyModel3 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model3+\".pickle\",'rb'))\n",
    "        weights3 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model3+\".weights\",'rb'))\n",
    "\n",
    "        weights =  weights3 # Go for the most destabilizing off target\n",
    "        weights[0] = -1 # Don't include the offset...\n",
    "\n",
    "        for threshold in [0]:\n",
    "            print(threshold)\n",
    "            \n",
    "            # defines the problem\n",
    "            prob = LpProblem(\"problem\", LpMaximize) #########<<<<<<<<<<<<<<<<<<<<< MAXIMIZE\n",
    "            addLinearConstraint_Forbiden(prob,allVariables)\n",
    "            addLinearConstraintsPulp(22,prob,allVariables)\n",
    "            addPairConstraintsPulp(22,prob,allVariables)\n",
    "\n",
    "\n",
    "\n",
    "            ############# \n",
    "            #Affinity Constraints\n",
    "            #\n",
    "            #Affinity for target must be tighter than \n",
    "            #prob += LpAffineExpression((allVariables[k],weights1[k]) for k in range(len(allVariables))) <= -10 -polyModel1.intercept_[0]\n",
    "            #prob += LpAffineExpression((allVariables[k],weights2[k]) for k in range(len(allVariables))) <= -10 -polyModel2.intercept_[0]\n",
    "            #Affinity for offtarget must be less than \n",
    "            #prob += LpAffineExpression((allVariables[k],weights3[k]) for k in range(len(allVariables))) >= -8.5 -polyModel3.intercept_[0]\n",
    "            #\n",
    "            #############\n",
    "\n",
    "            #############\n",
    "            # Specificity Constraints\n",
    "            #\n",
    "            # (This determines the angle)  (-1 to 1) is the ratio of the two\n",
    "            dualWeights = weights1-weights2\n",
    "            dualIntercepts = polyModel1.intercept_[0]- polyModel2.intercept_[0]\n",
    "            prob+= LpAffineExpression((allVariables[k],dualWeights[k]) for k in range(len(allVariables))) <= threshold+0.2 - dualIntercepts\n",
    "            prob+= LpAffineExpression((allVariables[k],dualWeights[k]) for k in range(len(allVariables))) >= threshold-0.2 - dualIntercepts\n",
    "            #\n",
    "            #############\n",
    "\n",
    "            #Problem to Solve For\n",
    "            # Maximize the difference \n",
    "            dualWeights_affinity = weights3-weights1\n",
    "            dualWeights_affinity[0] = -1\n",
    "            prob += LpAffineExpression((allVariables[k],dualWeights_affinity[k]) for k in range(len(allVariables)))\n",
    "            #prob += LpAffineExpression((allVariables[k],weights[k]) for k in range(len(allVariables)))\n",
    "\n",
    "\n",
    "            topX = []\n",
    "            for iteration in range(200):\n",
    "\n",
    "                status = prob.solve(cplexSolver)\n",
    "                LpStatus[status]\n",
    "\n",
    "                if(LpStatus[status]=='Optimal'):                \n",
    "\n",
    "                    allValues = [(idx,i,value(i)) for idx,i in enumerate(allVariables) if np.abs(value(i))>10**-6]\n",
    "                    optSeq = \"\".join([str(allValues[i][1])[5:] for i in range(0,22)])\n",
    "\n",
    "                    prob+= lpSum([allVariables[allValues[i][0]] for i in range(22)]) <= 21\n",
    "\n",
    "\n",
    "\n",
    "                    #optSeq = receptor1+\"_\"+receptor2+str(iteration)\n",
    "\n",
    "                    topX.append(optSeq)\n",
    "\n",
    "                    #optSeqScore1 = polyModel1.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                    #optSeqScore2 = polyModel2.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                    #optSeqScore3 = polyModel3.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "\n",
    "                    outFile.write(topX[-1])\n",
    "                    outFile.write(\"\\n\")\n",
    "                    outFile.flush()\n",
    "                else:\n",
    "                    outFile.write(LpStatus[status])\n",
    "                    outFile.flush()\n",
    "                    break\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /home/vxue/data/sort_specificity/design_y/scripts/final/09.5a.py\n",
    "\n",
    "\n",
    "from pulp import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "aminoAcidIndex = 'ACEDGFIHKMLNQPSRTWVY'\n",
    "myPosLabels=['1E','1F','1G','2A','2B','2C','2D','2E','2F','2G','3A','3B','3C','3D','3E','3F','3G','4A','4B','4C','4D','4E']\n",
    "\n",
    "\n",
    "def kcalToKD(i):\n",
    "    return np.e**(i/ ((1.9872041 * 10**-3)  * (298))) * 10**9\n",
    "\n",
    "###############################\n",
    "# Define ILP Functions to generate constraints\n",
    "###############################\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addLinearConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    \n",
    "    allSingleAAConstraints = []\n",
    "    \n",
    "    for i in range(numAA):\n",
    "        #blank = np.zeros(int((numAA*20)+((numAA*20)*((numAA*20)+1)/2)))\n",
    "        prob+=lpSum(allVariables[i*20+j+offset] for j in range(20)) == 1\n",
    "    \n",
    "\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addPairConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    signs = [1,-1]        \n",
    "    arrayOffset = numAA*20\n",
    "    arrayDim = numAA*20\n",
    "    #Expanded Vector1\n",
    "    for i in range(numAA*20):\n",
    "        ##################################################\n",
    "        tempArray=[]\n",
    "        #Expanded Vector2        \n",
    "        for j in range(i,numAA*20):\n",
    "\n",
    "            if(j%20==0 and j!=i): # For each set of 20, add another constraint\n",
    "                \n",
    "                tempArray.append((allVariables[i+offset],-1)) # AA constraint for single term\n",
    "                prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "                tempArray=[]\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "            else:\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "\n",
    "        \n",
    "            arrayOffset+=1\n",
    "            \n",
    "        tempArray.append((allVariables[i+offset],-1))   \n",
    "        prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "        ##################################################\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Second Set of constraints to assure second variable is stable\n",
    "        #################################################\n",
    "        \n",
    "        \n",
    "        tempArray2=[]\n",
    "        #print(allVariables[i+offset], \"=============\", i)\n",
    "        \n",
    "        for k in range(i+1): # k is the number of times to add pair terms\n",
    "            \n",
    "            if(k>1 and k%20==0): #every 20, add another constraint that at most one pair can be selected\n",
    "                \n",
    "                # Assert that feature occurs as singleton\n",
    "                tempArray2.append((allVariables[i+offset],-1))  \n",
    "                prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "                tempArray2=[]\n",
    "            \n",
    "\n",
    "            tempArray2.append((allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],1))\n",
    "            #These calculations help get the index of the next pair term \n",
    "            \n",
    "        \n",
    "            #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],end=\" \")\n",
    " \n",
    "        \n",
    "        #When complete, top it off and add the last set of constraints\n",
    "        tempArray2.append((allVariables[i+offset],-1))\n",
    "        #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],k,end=\" \")\n",
    "        prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "        \n",
    "        \n",
    "def getPolyExpansionLabels(inputVector):\n",
    "    \n",
    "    myLabels = []\n",
    "    \n",
    "\n",
    "    myDegree = 2\n",
    "    myNewVector=[]\n",
    "    \n",
    "    myLabels.append('Offset')\n",
    "    for idx,each in enumerate(inputVector):\n",
    "        myNewVector.append(np.sqrt(2)*each)\n",
    "        myLabels.append(myPosLabels[idx//20]+\"_\"+aminoAcidIndex[idx%20])\n",
    "    \n",
    "    for i in range(len(inputVector)):\n",
    "        for j in range(i,len(inputVector)):\n",
    "            \n",
    "            myLabels.append(myPosLabels[i//20]+\"_\"+aminoAcidIndex[i%20]+\"__\"+\n",
    "            myPosLabels[j//20]+\"_\"+aminoAcidIndex[j%20])\n",
    "    \n",
    "    return myLabels\n",
    "\n",
    "def getK(dim,iteration):\n",
    "    mySum = 0\n",
    "    for i in range(1,iteration+1):\n",
    "        mySum+= (dim-i)\n",
    "    return mySum\n",
    "\n",
    "###############################\n",
    "# Define Dummy Variable Encoding\n",
    "###############################\n",
    "\n",
    "def getAAVector(letter):\n",
    "    vector = np.zeros(20);\n",
    "    vector[aminoAcidIndex.index(letter)]=1\n",
    "    return  vector\n",
    "\n",
    "def encodeWithDummyVariables(sequence):\n",
    "    newArray=[]\n",
    "    for aa in sequence:\n",
    "        newArray.append(getAAVector(aa))\n",
    "    return np.array(newArray).ravel()\n",
    "\n",
    "###############################\n",
    "# Define Constraints on Counts\n",
    "###############################\n",
    "def addLinearConstraint_Forbiden(prob,allVariables,inputCounts,threshold,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bim):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "        \n",
    "    for idx,each in enumerate(puma):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mixMut):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "    \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(inputCounts):\n",
    "        if(each)<threshold:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    disallowed = (~allowedArray.astype(bool)).astype(int)\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(disallowed):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "    \n",
    "    return allowedArray\n",
    "\n",
    "#############################\n",
    "# Define Library Constraints\n",
    "#############################\n",
    "\n",
    "bim = 'GRPEIWIAQELRRIGDEFNAYY'\n",
    "puma = 'GQWAREIGAQLRRMADDLNAQY'\n",
    "xMut = ['']*22\n",
    "xMut[3] = 'DEHIKLMNQV'\n",
    "xMut[6] ='DFHILNVY'\n",
    "xMut[11]='AGIRTV'\n",
    "xMut[13]='ADFGHILNPRSTVY' #C\n",
    "xMut[14]='AG'\n",
    "xMut[18]='ADHILNPTV'\n",
    "xMut[19]='AEKT'\n",
    "xMut[21]='ADGHNPRSTY' #C\n",
    "\n",
    "mMut = ['']*22\n",
    "mMut[2] = 'AGPRSTW'\n",
    "mMut[4]='ADFGHLPRSVY' #C\n",
    "mMut[5]='DEHQ'\n",
    "mMut[6]='AITV'\n",
    "mMut[7]='AGISTV'\n",
    "mMut[11]='AEGIKRTV'\n",
    "mMut[17]='ADFHILNPSTVY'\n",
    "mMut[18]='DEHKNQ'\n",
    "\n",
    "fMut = ['']*22\n",
    "fMut[3] = 'AEIKLPQTV'\n",
    "fMut[7]='ADGSY' #C\n",
    "fMut[9]='DFGHILNRSVY'# C\n",
    "fMut[13]='AFGILPRSTV' #C\n",
    "fMut[16]='DEHIKLMNQV'\n",
    "fMut[17]='ADFHILNPSTVY'\n",
    "fMut[21]='AFILPSTV'\n",
    "\n",
    "mixMut = []\n",
    "for i in range(22):\n",
    "    mixMut.append(set(xMut[i]).union(set(mMut[i])).union(set(fMut[i])))\n",
    "\n",
    "libVariables = [LpVariable(\"i_\"+j,0,22,LpInteger) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "libVariablesBinary = [LpVariable(\"b_\"+j,0,22,LpBinary) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "\n",
    "###############################\n",
    "# If Designing in the input library space use the following functions\n",
    "###############################\n",
    "\n",
    "def addLinearConstraintSingleLib(prob,allVariables,bgLib,mutAllowed,libVar,libVarBin,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bgLib):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mutAllowed):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "            \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<10:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(allowedArray):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == libVar\n",
    "    prob += libVar >= libVarBin*22 # libVarBin is 1 if libVar is >= 22\n",
    "    #Because of the other constraints - this is just a variable that assigns boolean == 22\n",
    "    \n",
    "    return tempArray\n",
    "    \n",
    "def addLinearConstraintMultipleLib(prob,allVariables,offset=1):\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,xMut,libVariables[0],libVariablesBinary[0],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,mMut,libVariables[1],libVariablesBinary[1],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,fMut,libVariables[2],libVariablesBinary[2],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,xMut,libVariables[3],libVariablesBinary[3],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,mMut,libVariables[4],libVariablesBinary[4],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,fMut,libVariables[5],libVariablesBinary[5],offset)\n",
    "def addLinearConstraint_library(prob,allVariables,offset=1):\n",
    "    prob+= lpSum(each for each in libVariablesBinary) >= 1\n",
    "    addLinearConstraintMultipleLib(prob,allVariables,offset)\n",
    "    #print(libVariables)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#############################\n",
    "# Start loading model specific reqs\n",
    "#############################\n",
    "\n",
    "allData,allDataName = pickle.load(open('/home/vxue/data/sort_specificity/ncv_y/allData.pickle','rb'))\n",
    "\n",
    "modelIndex = [allDataName.index(i) for i in ['all_x','all_s',\n",
    "                                             'all_m','all_n',\n",
    "                                             'all_f','all_t',\n",
    "                                             'all_z','all_c']]\n",
    "\n",
    "myIndex = [row+'_'+letter for row in myPosLabels for letter in aminoAcidIndex]\n",
    "\n",
    "#############################\n",
    "# Count the number of sequences\n",
    "#############################\n",
    "myCounts = dict()\n",
    "for each,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myCounts[name]=posAA_toCount\n",
    "\n",
    "    \n",
    "#############################\n",
    "# Count the number of sequences that have an affinity less than -10..5\n",
    "#############################\n",
    "myBindingCounts = dict()\n",
    "for each_full,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    #Count only the ones which have affinity less than ~50 nM\n",
    "    each = each_full[each_full.yValue < -10.5].copy().reset_index()\n",
    "    \n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myBindingCounts[name]=posAA_toCount\n",
    "    \n",
    "    \n",
    "    \n",
    "designsTargets = [  #Do the pairs by the ones that have the best cross validated performance\n",
    "    ('fn','x'),\n",
    "    ('nx','f'),\n",
    "    ('xf','n')]\n",
    "\n",
    "slurmInput =int(sys.argv[1])    \n",
    "\n",
    "\n",
    "cplexSolver = solvers.CPLEX_CMD(\"/scratch/users/mit_keating/Applications/CPLEX_Studio1271/cplex/bin/x86-64_linux/cplex\")\n",
    "\n",
    "for receptor1,receptor2 in [designsTargets[slurmInput]]:\n",
    "    \n",
    "    with open(\"/home/vxue/data/sort_specificity/design_y/specificity/trial11/9.5a/\"+receptor1+\"-\"+receptor2+\"_poly.csv\",'w') as outFile:\n",
    "        model1 = \"all_\"+receptor1[0]\n",
    "        model2 = \"all_\"+receptor1[1]\n",
    "        model3 = \"all_\"+receptor2\n",
    "\n",
    "\n",
    "        print(model1,model2,model3)\n",
    "        #Seq counts are set to the min of the three targets\n",
    "        aaCounts1  = [myCounts[model1][i] for i in myIndex]\n",
    "        aaCounts2  = [myCounts[model2][i] for i in myIndex]\n",
    "        aaCounts3  = [myCounts[model3][i] for i in myIndex]\n",
    "        aaCounts = min(aaCounts1,aaCounts2,aaCounts3)\n",
    "\n",
    "        #Binding counts are set to the min of the two targets\n",
    "        bindingCounts1 = [myBindingCounts[model1][i] for i in myIndex]\n",
    "        bindingCounts2 = [myBindingCounts[model2][i] for i in myIndex]\n",
    "        bindingCounts = min(bindingCounts1,bindingCounts2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        featureTable = getPolyExpansionLabels(np.ones(440))\n",
    "        allVariables=[LpVariable(\"x_\"+j,0,1,LpBinary) for j in featureTable]\n",
    "\n",
    "        polyModel1 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model1+\".pickle\",'rb'))\n",
    "        weights1 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model1+\".weights\",'rb'))\n",
    "        polyModel2 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model2+\".pickle\",'rb'))\n",
    "        weights2 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model2+\".weights\",'rb'))\n",
    "        polyModel3 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model3+\".pickle\",'rb'))\n",
    "        weights3 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model3+\".weights\",'rb'))\n",
    "\n",
    "        weights =  weights1 # Go for the most stabilizing target\n",
    "        weights[0] = 1 # Don't include the offset\n",
    "\n",
    "        for threshold in [0]:\n",
    "            print(threshold)\n",
    "            \n",
    "            # defines the problem\n",
    "            prob = LpProblem(\"problem\", LpMinimize)\n",
    "            addLinearConstraint_Forbiden(prob,allVariables,aaCounts,25)\n",
    "            addLinearConstraint_Forbiden(prob,allVariables,bindingCounts,1)\n",
    "            addLinearConstraintsPulp(22,prob,allVariables)\n",
    "            addPairConstraintsPulp(22,prob,allVariables)\n",
    "\n",
    "\n",
    "\n",
    "            ############# \n",
    "            #Affinity Constraints\n",
    "            #\n",
    "            #Affinity for target must be tighter than \n",
    "            prob += LpAffineExpression((allVariables[k],weights1[k]) for k in range(len(allVariables))) <= -11.3 -polyModel1.intercept_[0]\n",
    "            prob += LpAffineExpression((allVariables[k],weights2[k]) for k in range(len(allVariables))) <= -11.3 -polyModel2.intercept_[0]\n",
    "            #Affinity for offtarget must be less than \n",
    "            prob += LpAffineExpression((allVariables[k],weights3[k]) for k in range(len(allVariables))) >= -9.5 -polyModel3.intercept_[0]\n",
    "            #\n",
    "            #############\n",
    "\n",
    "            #############\n",
    "            # Specificity Constraints\n",
    "            #\n",
    "            # (This determines the angle)  (-1 to 1) is the ratio of the two\n",
    "            #dualWeights = weights1-weights2\n",
    "            #dualIntercepts = polyModel1.intercept_[0]- polyModel2.intercept_[0]\n",
    "            #prob+= LpAffineExpression((allVariables[k],dualWeights[k]) for k in range(len(allVariables))) <= threshold+0.2 - dualIntercepts\n",
    "            #prob+= LpAffineExpression((allVariables[k],dualWeights[k]) for k in range(len(allVariables))) >= threshold-0.2 - dualIntercepts\n",
    "            #\n",
    "            #############\n",
    "\n",
    "            #Problem to Solve For\n",
    "            # Maximize the difference \n",
    "            #dualWeights_affinity = weights3-weights1\n",
    "            #dualWeights_affinity[0] = -1\n",
    "            #prob += LpAffineExpression((allVariables[k],dualWeights_affinity[k]) for k in range(len(allVariables)))\n",
    "            prob += LpAffineExpression((allVariables[k],weights[k]) for k in range(len(allVariables)))\n",
    "\n",
    "\n",
    "            topX = []\n",
    "            for iteration in range(200):\n",
    "\n",
    "                status = prob.solve(cplexSolver)\n",
    "                LpStatus[status]\n",
    "\n",
    "                if(LpStatus[status]=='Optimal'):                \n",
    "\n",
    "                    allValues = [(idx,i,value(i)) for idx,i in enumerate(allVariables) if np.abs(value(i))>10**-6]\n",
    "                    optSeq = \"\".join([str(allValues[i][1])[5:] for i in range(0,22)])\n",
    "\n",
    "                    prob+= lpSum([allVariables[allValues[i][0]] for i in range(22)]) <= 21\n",
    "\n",
    "\n",
    "\n",
    "                    #optSeq = receptor1+\"_\"+receptor2+str(iteration)\n",
    "\n",
    "                    topX.append(optSeq)\n",
    "\n",
    "                    #optSeqScore1 = polyModel1.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                    #optSeqScore2 = polyModel2.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                    #optSeqScore3 = polyModel3.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "\n",
    "                    outFile.write(topX[-1])\n",
    "                    outFile.write(\"\\n\")\n",
    "                    outFile.flush()\n",
    "                else:\n",
    "                    outFile.write(LpStatus[status])\n",
    "                    outFile.flush()\n",
    "                    break\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /home/vxue/data/sort_specificity/design_y/scripts/final/10a.py\n",
    "\n",
    "\n",
    "from pulp import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "aminoAcidIndex = 'ACEDGFIHKMLNQPSRTWVY'\n",
    "myPosLabels=['1E','1F','1G','2A','2B','2C','2D','2E','2F','2G','3A','3B','3C','3D','3E','3F','3G','4A','4B','4C','4D','4E']\n",
    "\n",
    "\n",
    "def kcalToKD(i):\n",
    "    return np.e**(i/ ((1.9872041 * 10**-3)  * (298))) * 10**9\n",
    "\n",
    "###############################\n",
    "# Define ILP Functions to generate constraints\n",
    "###############################\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addLinearConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    \n",
    "    allSingleAAConstraints = []\n",
    "    \n",
    "    for i in range(numAA):\n",
    "        #blank = np.zeros(int((numAA*20)+((numAA*20)*((numAA*20)+1)/2)))\n",
    "        prob+=lpSum(allVariables[i*20+j+offset] for j in range(20)) == 1\n",
    "    \n",
    "\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addPairConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    signs = [1,-1]        \n",
    "    arrayOffset = numAA*20\n",
    "    arrayDim = numAA*20\n",
    "    #Expanded Vector1\n",
    "    for i in range(numAA*20):\n",
    "        ##################################################\n",
    "        tempArray=[]\n",
    "        #Expanded Vector2        \n",
    "        for j in range(i,numAA*20):\n",
    "\n",
    "            if(j%20==0 and j!=i): # For each set of 20, add another constraint\n",
    "                \n",
    "                tempArray.append((allVariables[i+offset],-1)) # AA constraint for single term\n",
    "                prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "                tempArray=[]\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "            else:\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "\n",
    "        \n",
    "            arrayOffset+=1\n",
    "            \n",
    "        tempArray.append((allVariables[i+offset],-1))   \n",
    "        prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "        ##################################################\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Second Set of constraints to assure second variable is stable\n",
    "        #################################################\n",
    "        \n",
    "        \n",
    "        tempArray2=[]\n",
    "        #print(allVariables[i+offset], \"=============\", i)\n",
    "        \n",
    "        for k in range(i+1): # k is the number of times to add pair terms\n",
    "            \n",
    "            if(k>1 and k%20==0): #every 20, add another constraint that at most one pair can be selected\n",
    "                \n",
    "                # Assert that feature occurs as singleton\n",
    "                tempArray2.append((allVariables[i+offset],-1))  \n",
    "                prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "                tempArray2=[]\n",
    "            \n",
    "\n",
    "            tempArray2.append((allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],1))\n",
    "            #These calculations help get the index of the next pair term \n",
    "            \n",
    "        \n",
    "            #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],end=\" \")\n",
    " \n",
    "        \n",
    "        #When complete, top it off and add the last set of constraints\n",
    "        tempArray2.append((allVariables[i+offset],-1))\n",
    "        #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],k,end=\" \")\n",
    "        prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "        \n",
    "        \n",
    "def getPolyExpansionLabels(inputVector):\n",
    "    \n",
    "    myLabels = []\n",
    "    \n",
    "\n",
    "    myDegree = 2\n",
    "    myNewVector=[]\n",
    "    \n",
    "    myLabels.append('Offset')\n",
    "    for idx,each in enumerate(inputVector):\n",
    "        myNewVector.append(np.sqrt(2)*each)\n",
    "        myLabels.append(myPosLabels[idx//20]+\"_\"+aminoAcidIndex[idx%20])\n",
    "    \n",
    "    for i in range(len(inputVector)):\n",
    "        for j in range(i,len(inputVector)):\n",
    "            \n",
    "            myLabels.append(myPosLabels[i//20]+\"_\"+aminoAcidIndex[i%20]+\"__\"+\n",
    "            myPosLabels[j//20]+\"_\"+aminoAcidIndex[j%20])\n",
    "    \n",
    "    return myLabels\n",
    "\n",
    "def getK(dim,iteration):\n",
    "    mySum = 0\n",
    "    for i in range(1,iteration+1):\n",
    "        mySum+= (dim-i)\n",
    "    return mySum\n",
    "\n",
    "###############################\n",
    "# Define Dummy Variable Encoding\n",
    "###############################\n",
    "\n",
    "def getAAVector(letter):\n",
    "    vector = np.zeros(20);\n",
    "    vector[aminoAcidIndex.index(letter)]=1\n",
    "    return  vector\n",
    "\n",
    "def encodeWithDummyVariables(sequence):\n",
    "    newArray=[]\n",
    "    for aa in sequence:\n",
    "        newArray.append(getAAVector(aa))\n",
    "    return np.array(newArray).ravel()\n",
    "\n",
    "###############################\n",
    "# Define Constraints on Counts\n",
    "###############################\n",
    "def addLinearConstraint_Forbiden(prob,allVariables,inputCounts,threshold,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bim):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "        \n",
    "    for idx,each in enumerate(puma):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mixMut):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "    \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(inputCounts):\n",
    "        if(each)<threshold:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    disallowed = (~allowedArray.astype(bool)).astype(int)\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(disallowed):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "    \n",
    "    return allowedArray\n",
    "\n",
    "#############################\n",
    "# Define Library Constraints\n",
    "#############################\n",
    "\n",
    "bim = 'GRPEIWIAQELRRIGDEFNAYY'\n",
    "puma = 'GQWAREIGAQLRRMADDLNAQY'\n",
    "xMut = ['']*22\n",
    "xMut[3] = 'DEHIKLMNQV'\n",
    "xMut[6] ='DFHILNVY'\n",
    "xMut[11]='AGIRTV'\n",
    "xMut[13]='ADFGHILNPRSTVY' #C\n",
    "xMut[14]='AG'\n",
    "xMut[18]='ADHILNPTV'\n",
    "xMut[19]='AEKT'\n",
    "xMut[21]='ADGHNPRSTY' #C\n",
    "\n",
    "mMut = ['']*22\n",
    "mMut[2] = 'AGPRSTW'\n",
    "mMut[4]='ADFGHLPRSVY' #C\n",
    "mMut[5]='DEHQ'\n",
    "mMut[6]='AITV'\n",
    "mMut[7]='AGISTV'\n",
    "mMut[11]='AEGIKRTV'\n",
    "mMut[17]='ADFHILNPSTVY'\n",
    "mMut[18]='DEHKNQ'\n",
    "\n",
    "fMut = ['']*22\n",
    "fMut[3] = 'AEIKLPQTV'\n",
    "fMut[7]='ADGSY' #C\n",
    "fMut[9]='DFGHILNRSVY'# C\n",
    "fMut[13]='AFGILPRSTV' #C\n",
    "fMut[16]='DEHIKLMNQV'\n",
    "fMut[17]='ADFHILNPSTVY'\n",
    "fMut[21]='AFILPSTV'\n",
    "\n",
    "mixMut = []\n",
    "for i in range(22):\n",
    "    mixMut.append(set(xMut[i]).union(set(mMut[i])).union(set(fMut[i])))\n",
    "\n",
    "libVariables = [LpVariable(\"i_\"+j,0,22,LpInteger) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "libVariablesBinary = [LpVariable(\"b_\"+j,0,22,LpBinary) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "\n",
    "###############################\n",
    "# If Designing in the input library space use the following functions\n",
    "###############################\n",
    "\n",
    "def addLinearConstraintSingleLib(prob,allVariables,bgLib,mutAllowed,libVar,libVarBin,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bgLib):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mutAllowed):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "            \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<10:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(allowedArray):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == libVar\n",
    "    prob += libVar >= libVarBin*22 # libVarBin is 1 if libVar is >= 22\n",
    "    #Because of the other constraints - this is just a variable that assigns boolean == 22\n",
    "    \n",
    "    return tempArray\n",
    "    \n",
    "def addLinearConstraintMultipleLib(prob,allVariables,offset=1):\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,xMut,libVariables[0],libVariablesBinary[0],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,mMut,libVariables[1],libVariablesBinary[1],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,fMut,libVariables[2],libVariablesBinary[2],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,xMut,libVariables[3],libVariablesBinary[3],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,mMut,libVariables[4],libVariablesBinary[4],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,fMut,libVariables[5],libVariablesBinary[5],offset)\n",
    "def addLinearConstraint_library(prob,allVariables,offset=1):\n",
    "    prob+= lpSum(each for each in libVariablesBinary) >= 1\n",
    "    addLinearConstraintMultipleLib(prob,allVariables,offset)\n",
    "    #print(libVariables)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#############################\n",
    "# Start loading model specific reqs\n",
    "#############################\n",
    "\n",
    "allData,allDataName = pickle.load(open('/home/vxue/data/sort_specificity/ncv_y/allData.pickle','rb'))\n",
    "\n",
    "modelIndex = [allDataName.index(i) for i in ['all_x','all_s',\n",
    "                                             'all_m','all_n',\n",
    "                                             'all_f','all_t',\n",
    "                                             'all_z','all_c']]\n",
    "\n",
    "myIndex = [row+'_'+letter for row in myPosLabels for letter in aminoAcidIndex]\n",
    "\n",
    "#############################\n",
    "# Count the number of sequences\n",
    "#############################\n",
    "myCounts = dict()\n",
    "for each,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myCounts[name]=posAA_toCount\n",
    "\n",
    "    \n",
    "#############################\n",
    "# Count the number of sequences that have an affinity less than -10..5\n",
    "#############################\n",
    "myBindingCounts = dict()\n",
    "for each_full,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    #Count only the ones which have affinity less than ~50 nM\n",
    "    each = each_full[each_full.yValue < -10.5].copy().reset_index()\n",
    "    \n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myBindingCounts[name]=posAA_toCount\n",
    "    \n",
    "    \n",
    "    \n",
    "designsTargets = [  #Do the pairs by the ones that have the best cross validated performance\n",
    "    ('fn','x'),\n",
    "    ('nx','f'),\n",
    "    ('xf','n')]\n",
    "\n",
    "slurmInput =int(sys.argv[1])    \n",
    "\n",
    "\n",
    "cplexSolver = solvers.CPLEX_CMD(\"/scratch/users/mit_keating/Applications/CPLEX_Studio1271/cplex/bin/x86-64_linux/cplex\")\n",
    "\n",
    "for receptor1,receptor2 in [designsTargets[slurmInput]]:\n",
    "    \n",
    "    with open(\"/home/vxue/data/sort_specificity/design_y/specificity/trial11/10a/\"+receptor1+\"-\"+receptor2+\"_poly.csv\",'w') as outFile:\n",
    "        model1 = \"all_\"+receptor1[0]\n",
    "        model2 = \"all_\"+receptor1[1]\n",
    "        model3 = \"all_\"+receptor2\n",
    "\n",
    "\n",
    "        print(model1,model2,model3)\n",
    "        #Seq counts are set to the min of the three targets\n",
    "        aaCounts1  = [myCounts[model1][i] for i in myIndex]\n",
    "        aaCounts2  = [myCounts[model2][i] for i in myIndex]\n",
    "        aaCounts3  = [myCounts[model3][i] for i in myIndex]\n",
    "        aaCounts = min(aaCounts1,aaCounts2,aaCounts3)\n",
    "\n",
    "        #Binding counts are set to the min of the two targets\n",
    "        bindingCounts1 = [myBindingCounts[model1][i] for i in myIndex]\n",
    "        bindingCounts2 = [myBindingCounts[model2][i] for i in myIndex]\n",
    "        bindingCounts = min(bindingCounts1,bindingCounts2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        featureTable = getPolyExpansionLabels(np.ones(440))\n",
    "        allVariables=[LpVariable(\"x_\"+j,0,1,LpBinary) for j in featureTable]\n",
    "\n",
    "        polyModel1 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model1+\".pickle\",'rb'))\n",
    "        weights1 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model1+\".weights\",'rb'))\n",
    "        polyModel2 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model2+\".pickle\",'rb'))\n",
    "        weights2 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model2+\".weights\",'rb'))\n",
    "        polyModel3 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model3+\".pickle\",'rb'))\n",
    "        weights3 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model3+\".weights\",'rb'))\n",
    "\n",
    "        weights =  weights1 # Go for the most stabilizing target\n",
    "        weights[0] = 1 # Don't include the offset\n",
    "\n",
    "        for threshold in [0]:\n",
    "            print(threshold)\n",
    "            \n",
    "            # defines the problem\n",
    "            prob = LpProblem(\"problem\", LpMinimize)\n",
    "            addLinearConstraint_Forbiden(prob,allVariables,aaCounts,25)\n",
    "            addLinearConstraint_Forbiden(prob,allVariables,bindingCounts,1)\n",
    "            addLinearConstraintsPulp(22,prob,allVariables)\n",
    "            addPairConstraintsPulp(22,prob,allVariables)\n",
    "\n",
    "\n",
    "\n",
    "            ############# \n",
    "            #Affinity Constraints\n",
    "            #\n",
    "            #Affinity for target must be tighter than \n",
    "            prob += LpAffineExpression((allVariables[k],weights1[k]) for k in range(len(allVariables))) <= -11.3 -polyModel1.intercept_[0]\n",
    "            prob += LpAffineExpression((allVariables[k],weights2[k]) for k in range(len(allVariables))) <= -11.3 -polyModel2.intercept_[0]\n",
    "            #Affinity for offtarget must be less than \n",
    "            prob += LpAffineExpression((allVariables[k],weights3[k]) for k in range(len(allVariables))) >= -10 -polyModel3.intercept_[0]\n",
    "            #\n",
    "            #############\n",
    "\n",
    "            #############\n",
    "            # Specificity Constraints\n",
    "            #\n",
    "            # (This determines the angle)  (-1 to 1) is the ratio of the two\n",
    "            #dualWeights = weights1-weights2\n",
    "            #dualIntercepts = polyModel1.intercept_[0]- polyModel2.intercept_[0]\n",
    "            #prob+= LpAffineExpression((allVariables[k],dualWeights[k]) for k in range(len(allVariables))) <= threshold+0.2 - dualIntercepts\n",
    "            #prob+= LpAffineExpression((allVariables[k],dualWeights[k]) for k in range(len(allVariables))) >= threshold-0.2 - dualIntercepts\n",
    "            #\n",
    "            #############\n",
    "\n",
    "            #Problem to Solve For\n",
    "            # Maximize the difference \n",
    "            #dualWeights_affinity = weights3-weights1\n",
    "            #dualWeights_affinity[0] = -1\n",
    "            #prob += LpAffineExpression((allVariables[k],dualWeights_affinity[k]) for k in range(len(allVariables)))\n",
    "            prob += LpAffineExpression((allVariables[k],weights[k]) for k in range(len(allVariables)))\n",
    "\n",
    "\n",
    "            topX = []\n",
    "            for iteration in range(200):\n",
    "\n",
    "                status = prob.solve(cplexSolver)\n",
    "                LpStatus[status]\n",
    "\n",
    "                if(LpStatus[status]=='Optimal'):                \n",
    "\n",
    "                    allValues = [(idx,i,value(i)) for idx,i in enumerate(allVariables) if np.abs(value(i))>10**-6]\n",
    "                    optSeq = \"\".join([str(allValues[i][1])[5:] for i in range(0,22)])\n",
    "\n",
    "                    prob+= lpSum([allVariables[allValues[i][0]] for i in range(22)]) <= 21\n",
    "\n",
    "\n",
    "\n",
    "                    #optSeq = receptor1+\"_\"+receptor2+str(iteration)\n",
    "\n",
    "                    topX.append(optSeq)\n",
    "\n",
    "                    #optSeqScore1 = polyModel1.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                    #optSeqScore2 = polyModel2.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                    #optSeqScore3 = polyModel3.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "\n",
    "                    outFile.write(topX[-1])\n",
    "                    outFile.write(\"\\n\")\n",
    "                    outFile.flush()\n",
    "                else:\n",
    "                    outFile.write(LpStatus[status])\n",
    "                    outFile.flush()\n",
    "                    break\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load /home/vxue/data/sort_specificity/design_y/scripts/final/10b.py\n",
    "\n",
    "\n",
    "from pulp import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "aminoAcidIndex = 'ACEDGFIHKMLNQPSRTWVY'\n",
    "myPosLabels=['1E','1F','1G','2A','2B','2C','2D','2E','2F','2G','3A','3B','3C','3D','3E','3F','3G','4A','4B','4C','4D','4E']\n",
    "\n",
    "\n",
    "def kcalToKD(i):\n",
    "    return np.e**(i/ ((1.9872041 * 10**-3)  * (298))) * 10**9\n",
    "\n",
    "###############################\n",
    "# Define ILP Functions to generate constraints\n",
    "###############################\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addLinearConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    \n",
    "    allSingleAAConstraints = []\n",
    "    \n",
    "    for i in range(numAA):\n",
    "        #blank = np.zeros(int((numAA*20)+((numAA*20)*((numAA*20)+1)/2)))\n",
    "        prob+=lpSum(allVariables[i*20+j+offset] for j in range(20)) == 1\n",
    "    \n",
    "\n",
    "\n",
    "#Assuming 2 degree.\n",
    "def addPairConstraintsPulp(numAA,prob,allVariables,offset=1):\n",
    "    signs = [1,-1]        \n",
    "    arrayOffset = numAA*20\n",
    "    arrayDim = numAA*20\n",
    "    #Expanded Vector1\n",
    "    for i in range(numAA*20):\n",
    "        ##################################################\n",
    "        tempArray=[]\n",
    "        #Expanded Vector2        \n",
    "        for j in range(i,numAA*20):\n",
    "\n",
    "            if(j%20==0 and j!=i): # For each set of 20, add another constraint\n",
    "                \n",
    "                tempArray.append((allVariables[i+offset],-1)) # AA constraint for single term\n",
    "                prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "                tempArray=[]\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "            else:\n",
    "                tempArray.append((allVariables[arrayOffset+offset],1))\n",
    "\n",
    "        \n",
    "            arrayOffset+=1\n",
    "            \n",
    "        tempArray.append((allVariables[i+offset],-1))   \n",
    "        prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "        ##################################################\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Second Set of constraints to assure second variable is stable\n",
    "        #################################################\n",
    "        \n",
    "        \n",
    "        tempArray2=[]\n",
    "        #print(allVariables[i+offset], \"=============\", i)\n",
    "        \n",
    "        for k in range(i+1): # k is the number of times to add pair terms\n",
    "            \n",
    "            if(k>1 and k%20==0): #every 20, add another constraint that at most one pair can be selected\n",
    "                \n",
    "                # Assert that feature occurs as singleton\n",
    "                tempArray2.append((allVariables[i+offset],-1))  \n",
    "                prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "                tempArray2=[]\n",
    "            \n",
    "\n",
    "            tempArray2.append((allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],1))\n",
    "            #These calculations help get the index of the next pair term \n",
    "            \n",
    "        \n",
    "            #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],end=\" \")\n",
    " \n",
    "        \n",
    "        #When complete, top it off and add the last set of constraints\n",
    "        tempArray2.append((allVariables[i+offset],-1))\n",
    "        #print(allVariables[(arrayDim+offset+i+ getK(arrayDim,k))],k,end=\" \")\n",
    "        prob += LpAffineExpression(each for each in tempArray2) == 0\n",
    "        \n",
    "        \n",
    "def getPolyExpansionLabels(inputVector):\n",
    "    \n",
    "    myLabels = []\n",
    "    \n",
    "\n",
    "    myDegree = 2\n",
    "    myNewVector=[]\n",
    "    \n",
    "    myLabels.append('Offset')\n",
    "    for idx,each in enumerate(inputVector):\n",
    "        myNewVector.append(np.sqrt(2)*each)\n",
    "        myLabels.append(myPosLabels[idx//20]+\"_\"+aminoAcidIndex[idx%20])\n",
    "    \n",
    "    for i in range(len(inputVector)):\n",
    "        for j in range(i,len(inputVector)):\n",
    "            \n",
    "            myLabels.append(myPosLabels[i//20]+\"_\"+aminoAcidIndex[i%20]+\"__\"+\n",
    "            myPosLabels[j//20]+\"_\"+aminoAcidIndex[j%20])\n",
    "    \n",
    "    return myLabels\n",
    "\n",
    "def getK(dim,iteration):\n",
    "    mySum = 0\n",
    "    for i in range(1,iteration+1):\n",
    "        mySum+= (dim-i)\n",
    "    return mySum\n",
    "\n",
    "###############################\n",
    "# Define Dummy Variable Encoding\n",
    "###############################\n",
    "\n",
    "def getAAVector(letter):\n",
    "    vector = np.zeros(20);\n",
    "    vector[aminoAcidIndex.index(letter)]=1\n",
    "    return  vector\n",
    "\n",
    "def encodeWithDummyVariables(sequence):\n",
    "    newArray=[]\n",
    "    for aa in sequence:\n",
    "        newArray.append(getAAVector(aa))\n",
    "    return np.array(newArray).ravel()\n",
    "\n",
    "###############################\n",
    "# Define Constraints on Counts\n",
    "###############################\n",
    "def addLinearConstraint_Forbiden(prob,allVariables,inputCounts,threshold,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bim):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "        \n",
    "    for idx,each in enumerate(puma):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mixMut):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "    \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(inputCounts):\n",
    "        if(each)<threshold:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    disallowed = (~allowedArray.astype(bool)).astype(int)\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(disallowed):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == 0\n",
    "    \n",
    "    return allowedArray\n",
    "\n",
    "#############################\n",
    "# Define Library Constraints\n",
    "#############################\n",
    "\n",
    "bim = 'GRPEIWIAQELRRIGDEFNAYY'\n",
    "puma = 'GQWAREIGAQLRRMADDLNAQY'\n",
    "xMut = ['']*22\n",
    "xMut[3] = 'DEHIKLMNQV'\n",
    "xMut[6] ='DFHILNVY'\n",
    "xMut[11]='AGIRTV'\n",
    "xMut[13]='ADFGHILNPRSTVY' #C\n",
    "xMut[14]='AG'\n",
    "xMut[18]='ADHILNPTV'\n",
    "xMut[19]='AEKT'\n",
    "xMut[21]='ADGHNPRSTY' #C\n",
    "\n",
    "mMut = ['']*22\n",
    "mMut[2] = 'AGPRSTW'\n",
    "mMut[4]='ADFGHLPRSVY' #C\n",
    "mMut[5]='DEHQ'\n",
    "mMut[6]='AITV'\n",
    "mMut[7]='AGISTV'\n",
    "mMut[11]='AEGIKRTV'\n",
    "mMut[17]='ADFHILNPSTVY'\n",
    "mMut[18]='DEHKNQ'\n",
    "\n",
    "fMut = ['']*22\n",
    "fMut[3] = 'AEIKLPQTV'\n",
    "fMut[7]='ADGSY' #C\n",
    "fMut[9]='DFGHILNRSVY'# C\n",
    "fMut[13]='AFGILPRSTV' #C\n",
    "fMut[16]='DEHIKLMNQV'\n",
    "fMut[17]='ADFHILNPSTVY'\n",
    "fMut[21]='AFILPSTV'\n",
    "\n",
    "mixMut = []\n",
    "for i in range(22):\n",
    "    mixMut.append(set(xMut[i]).union(set(mMut[i])).union(set(fMut[i])))\n",
    "\n",
    "libVariables = [LpVariable(\"i_\"+j,0,22,LpInteger) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "libVariablesBinary = [LpVariable(\"b_\"+j,0,22,LpBinary) for j in ['bx','bm','bf','px','pm','pf']] \n",
    "\n",
    "###############################\n",
    "# If Designing in the input library space use the following functions\n",
    "###############################\n",
    "\n",
    "def addLinearConstraintSingleLib(prob,allVariables,bgLib,mutAllowed,libVar,libVarBin,offset=1):\n",
    "    allowedArray = np.zeros(20*22)\n",
    "    #Permit Native Seqs\n",
    "    for idx,each in enumerate(bgLib):\n",
    "        allowedArray[20*idx+aminoAcidIndex.index(each)] = 1\n",
    "    \n",
    "    for site,mutations in enumerate(mutAllowed):\n",
    "        for each in mutations:\n",
    "            allowedArray[site*20+aminoAcidIndex.index(each)]=1\n",
    "            \n",
    "    #Disallow low frequency observations\n",
    "    for idx,each in enumerate(aaCounts):\n",
    "        if(each)<10:\n",
    "            allowedArray[idx]=0\n",
    "    \n",
    "    tempArray=[]\n",
    "    for idx,i in enumerate(allowedArray):\n",
    "        if(i==1):\n",
    "            tempArray.append((allVariables[idx+offset],1))   \n",
    "\n",
    "    #print(tempArray)\n",
    "    prob += LpAffineExpression(each for each in tempArray) == libVar\n",
    "    prob += libVar >= libVarBin*22 # libVarBin is 1 if libVar is >= 22\n",
    "    #Because of the other constraints - this is just a variable that assigns boolean == 22\n",
    "    \n",
    "    return tempArray\n",
    "    \n",
    "def addLinearConstraintMultipleLib(prob,allVariables,offset=1):\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,xMut,libVariables[0],libVariablesBinary[0],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,mMut,libVariables[1],libVariablesBinary[1],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,bim,fMut,libVariables[2],libVariablesBinary[2],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,xMut,libVariables[3],libVariablesBinary[3],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,mMut,libVariables[4],libVariablesBinary[4],offset)\n",
    "    addLinearConstraintSingleLib(prob,allVariables,puma,fMut,libVariables[5],libVariablesBinary[5],offset)\n",
    "def addLinearConstraint_library(prob,allVariables,offset=1):\n",
    "    prob+= lpSum(each for each in libVariablesBinary) >= 1\n",
    "    addLinearConstraintMultipleLib(prob,allVariables,offset)\n",
    "    #print(libVariables)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#############################\n",
    "# Start loading model specific reqs\n",
    "#############################\n",
    "\n",
    "allData,allDataName = pickle.load(open('/home/vxue/data/sort_specificity/ncv_y/allData.pickle','rb'))\n",
    "\n",
    "modelIndex = [allDataName.index(i) for i in ['all_x','all_s',\n",
    "                                             'all_m','all_n',\n",
    "                                             'all_f','all_t',\n",
    "                                             'all_z','all_c']]\n",
    "\n",
    "myIndex = [row+'_'+letter for row in myPosLabels for letter in aminoAcidIndex]\n",
    "\n",
    "#############################\n",
    "# Count the number of sequences\n",
    "#############################\n",
    "myCounts = dict()\n",
    "for each,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myCounts[name]=posAA_toCount\n",
    "\n",
    "    \n",
    "#############################\n",
    "# Count the number of sequences that have an affinity less than -10..5\n",
    "#############################\n",
    "myBindingCounts = dict()\n",
    "for each_full,name in zip([allData[i] for i in modelIndex],[allDataName[i] for i in modelIndex]):\n",
    "    #Count only the ones which have affinity less than ~50 nM\n",
    "    each = each_full[each_full.yValue < -10.5].copy().reset_index()\n",
    "    \n",
    "    each['aaEncoding'] = each.apply(lambda x: list(encodeWithDummyVariables(x.twentytwo)),axis=1)\n",
    "    myMatrix = np.array([np.array(i) for i in each.aaEncoding])\n",
    "    counts = myMatrix.sum(axis=0)\n",
    "    posAA_toCount = dict()\n",
    "    for i,count in zip(myIndex,counts):\n",
    "        posAA_toCount[i] = int(count)\n",
    "    myBindingCounts[name]=posAA_toCount\n",
    "    \n",
    "    \n",
    "    \n",
    "designsTargets = [  #Do the pairs by the ones that have the best cross validated performance\n",
    "    ('fn','x'),\n",
    "    ('nx','f'),\n",
    "    ('xf','n')]\n",
    "\n",
    "slurmInput =int(sys.argv[1])    \n",
    "\n",
    "\n",
    "cplexSolver = solvers.CPLEX_CMD(\"/scratch/users/mit_keating/Applications/CPLEX_Studio1271/cplex/bin/x86-64_linux/cplex\")\n",
    "\n",
    "for receptor1,receptor2 in [designsTargets[slurmInput]]:\n",
    "    \n",
    "    with open(\"/home/vxue/data/sort_specificity/design_y/specificity/trial11/10b/\"+receptor1+\"-\"+receptor2+\"_poly.csv\",'w') as outFile:\n",
    "        model1 = \"all_\"+receptor1[0]\n",
    "        model2 = \"all_\"+receptor1[1]\n",
    "        model3 = \"all_\"+receptor2\n",
    "\n",
    "\n",
    "        print(model1,model2,model3)\n",
    "        #Seq counts are set to the min of the three targets\n",
    "        aaCounts1  = [myCounts[model1][i] for i in myIndex]\n",
    "        aaCounts2  = [myCounts[model2][i] for i in myIndex]\n",
    "        aaCounts3  = [myCounts[model3][i] for i in myIndex]\n",
    "        aaCounts = min(aaCounts1,aaCounts2,aaCounts3)\n",
    "\n",
    "        #Binding counts are set to the min of the two targets\n",
    "        bindingCounts1 = [myBindingCounts[model1][i] for i in myIndex]\n",
    "        bindingCounts2 = [myBindingCounts[model2][i] for i in myIndex]\n",
    "        bindingCounts = min(bindingCounts1,bindingCounts2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        featureTable = getPolyExpansionLabels(np.ones(440))\n",
    "        allVariables=[LpVariable(\"x_\"+j,0,1,LpBinary) for j in featureTable]\n",
    "\n",
    "        polyModel1 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model1+\".pickle\",'rb'))\n",
    "        weights1 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model1+\".weights\",'rb'))\n",
    "        polyModel2 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model2+\".pickle\",'rb'))\n",
    "        weights2 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model2+\".weights\",'rb'))\n",
    "        polyModel3 = pickle.load(open(\"/home/vxue/data/sort_specificity/rmse_doubleSet/ncv_y/modelpoly\"+model3+\".pickle\",'rb'))\n",
    "        weights3 = pickle.load(open(\"/home/vxue/data/sort_specificity/design_y/weights/ncv_y.modelpoly\" +model3+\".weights\",'rb'))\n",
    "\n",
    "        weights =  weights2 # Go for the most stabilizing target\n",
    "        weights[0] = 1 # Don't include the offset\n",
    "\n",
    "        for threshold in [0]:\n",
    "            print(threshold)\n",
    "            \n",
    "            # defines the problem\n",
    "            prob = LpProblem(\"problem\", LpMinimize)\n",
    "            addLinearConstraint_Forbiden(prob,allVariables,aaCounts,25)\n",
    "            addLinearConstraint_Forbiden(prob,allVariables,bindingCounts,1)\n",
    "            addLinearConstraintsPulp(22,prob,allVariables)\n",
    "            addPairConstraintsPulp(22,prob,allVariables)\n",
    "\n",
    "\n",
    "\n",
    "            ############# \n",
    "            #Affinity Constraints\n",
    "            #\n",
    "            #Affinity for target must be tighter than \n",
    "            prob += LpAffineExpression((allVariables[k],weights1[k]) for k in range(len(allVariables))) <= -11.3 -polyModel1.intercept_[0]\n",
    "            prob += LpAffineExpression((allVariables[k],weights2[k]) for k in range(len(allVariables))) <= -11.3 -polyModel2.intercept_[0]\n",
    "            #Affinity for offtarget must be less than \n",
    "            prob += LpAffineExpression((allVariables[k],weights3[k]) for k in range(len(allVariables))) >= -10 -polyModel3.intercept_[0]\n",
    "            #\n",
    "            #############\n",
    "\n",
    "            #############\n",
    "            # Specificity Constraints\n",
    "            #\n",
    "            # (This determines the angle)  (-1 to 1) is the ratio of the two\n",
    "            #dualWeights = weights1-weights2\n",
    "            #dualIntercepts = polyModel1.intercept_[0]- polyModel2.intercept_[0]\n",
    "            #prob+= LpAffineExpression((allVariables[k],dualWeights[k]) for k in range(len(allVariables))) <= threshold+0.2 - dualIntercepts\n",
    "            #prob+= LpAffineExpression((allVariables[k],dualWeights[k]) for k in range(len(allVariables))) >= threshold-0.2 - dualIntercepts\n",
    "            #\n",
    "            #############\n",
    "\n",
    "            #Problem to Solve For\n",
    "            # Maximize the difference \n",
    "            #dualWeights_affinity = weights3-weights1\n",
    "            #dualWeights_affinity[0] = -1\n",
    "            #prob += LpAffineExpression((allVariables[k],dualWeights_affinity[k]) for k in range(len(allVariables)))\n",
    "            prob += LpAffineExpression((allVariables[k],weights[k]) for k in range(len(allVariables)))\n",
    "\n",
    "\n",
    "            topX = []\n",
    "            for iteration in range(200):\n",
    "\n",
    "                status = prob.solve(cplexSolver)\n",
    "                LpStatus[status]\n",
    "\n",
    "                if(LpStatus[status]=='Optimal'):                \n",
    "\n",
    "                    allValues = [(idx,i,value(i)) for idx,i in enumerate(allVariables) if np.abs(value(i))>10**-6]\n",
    "                    optSeq = \"\".join([str(allValues[i][1])[5:] for i in range(0,22)])\n",
    "\n",
    "                    prob+= lpSum([allVariables[allValues[i][0]] for i in range(22)]) <= 21\n",
    "\n",
    "\n",
    "\n",
    "                    #optSeq = receptor1+\"_\"+receptor2+str(iteration)\n",
    "\n",
    "                    topX.append(optSeq)\n",
    "\n",
    "                    #optSeqScore1 = polyModel1.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                    #optSeqScore2 = polyModel2.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "                    #optSeqScore3 = polyModel3.predict(encodeWithDummyVariables(optSeq).reshape(1,-1))[0]\n",
    "\n",
    "                    outFile.write(topX[-1])\n",
    "                    outFile.write(\"\\n\")\n",
    "                    outFile.flush()\n",
    "                else:\n",
    "                    outFile.write(LpStatus[status])\n",
    "                    outFile.flush()\n",
    "                    break\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
